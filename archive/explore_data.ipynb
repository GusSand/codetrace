{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import datasets\n",
    "import builtins\n",
    "import pandas as pd\n",
    "# from vllm import LLM, SamplingParams, AsyncLLMEngine, AsyncEngineArgs\n",
    "import os\n",
    "from typing import List\n",
    "import sys\n",
    "sys.path.append(\"/home/franlucc/projects/codetrace\")\n",
    "DIR=\"/home/franlucc/projects/codetrace\"\n",
    "EXPDIR=\"/mnt/ssd/franlucc\"\n",
    "from codetrace.utils import load\n",
    "from codetrace.type_inf_exp.py_mutator import IMPORT_STATEMENT_QUERY, get_captures\n",
    "import typing\n",
    "from codetrace.parsing_utils import placeholder_to_std_fmt, DEEPSEEK_FIM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Codellama completions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Dataset({\n",
       "     features: ['key', 'prefix', 'suffix', 'middle', 'correct', 'model', 'fim_type', 'fim_program', 'hexsha', 'generated_text'],\n",
       "     num_rows: 125507\n",
       " }),\n",
       " Dataset({\n",
       "     features: ['key', 'prefix', 'suffix', 'middle', 'correct', 'model', 'fim_type', 'fim_program', 'hexsha'],\n",
       "     num_rows: 265879\n",
       " }))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "ds = datasets.load_from_disk(f\"{DIR}/experiments/codellama_7b/py_completions\")\n",
    "ds_sc1_ = datasets.load_dataset(\"nuprl-staging/py_typeinf_fim\", split=\"train\")\n",
    "ds, ds_sc1_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "hexshas = set(ds[\"fim_program\"])\n",
    "ds_sc1 = ds_sc1_.filter(lambda x: x[\"fim_program\"] in hexshas, num_proc=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct\n",
      "True     118953\n",
      "False      6554\n",
      "Name: count, dtype: int64 0.9477798051104719\n",
      "correct\n",
      "True     134511\n",
      "False    131368\n",
      "Name: count, dtype: int64 0.5059105833856754\n",
      "correct\n",
      "False    113228\n",
      "True      12279\n",
      "Name: count, dtype: int64 0.09783518050786012\n"
     ]
    }
   ],
   "source": [
    "df_sc1 = ds_sc1.to_pandas()\n",
    "df_sc1_ = ds_sc1_.to_pandas()\n",
    "df = ds.to_pandas()\n",
    "print(df_sc1[\"correct\"].value_counts(), df_sc1[\"correct\"].mean())\n",
    "print(df_sc1_[\"correct\"].value_counts(), df_sc1_[\"correct\"].mean())\n",
    "print(df[\"correct\"].value_counts(), df[\"correct\"].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_pattern(fim_type:str) -> str:\n",
    "    raw_pattern = r'from\\s+.+?\\s+import\\s+({fim_type})\\n|import\\s*.*?\\s+?({fim_type})\\n'\n",
    "    return raw_pattern.format(fim_type=fim_type)\n",
    "\n",
    "def is_imported(fim_type:str, fim_program:str) -> bool:\n",
    "    \n",
    "    matches = re.search(get_pattern(fim_type), fim_program)\n",
    "    if not matches:\n",
    "        return False\n",
    "    # print([matches.group(i) for i in range(1, len(matches.groups()) + 1)])\n",
    "    return any(matches.group(i) == fim_type for i in range(1, len(matches.groups()) + 1))\n",
    "\n",
    "def is_imported_ts(fim_type:str, fim_program:str)->bool:\n",
    "    prog = fim_program.replace(\"<FILL>\",\"_placeholder_\")\n",
    "    captures = get_captures(prog, IMPORT_STATEMENT_QUERY, \"py\", \"import_statement\")\n",
    "    for cap in captures:\n",
    "        imported_statements = cap.text.decode(\"utf-8\")\n",
    "        match = re.search(r'\\b({fim_type})\\b'.format(fim_type=fim_type), imported_statements)\n",
    "        if match != None:\n",
    "            return True\n",
    "    return False\n",
    "    \n",
    "def is_builtin(fim_type:str)->bool:\n",
    "    return any([fim_type==str(i) for i in dir(builtins)+dir(typing)])\n",
    "\n",
    "prog = '''from  oop import strop\n",
    "from oop.dilup import strop\n",
    "import Strofhsugf\n",
    "import igfhi from str\n",
    "\n",
    "from j import (\n",
    "    strop\n",
    ")\n",
    "\n",
    "from j.model import Integration, stroop\n",
    "\n",
    "'''\n",
    "is_imported_ts(\"s\", prog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=30): 100%|██████████| 125507/125507 [00:02<00:00, 45311.28 examples/s] \n"
     ]
    }
   ],
   "source": [
    "ds = ds.map(lambda x: {**x, \n",
    "                       \"is_imported_fim\" : is_imported(x[\"fim_type\"], x[\"fim_program\"]),\n",
    "                       \"is_builtin\": any([x[\"fim_type\"]==str(i) for i in dir(builtins)]),\n",
    "                       }, num_proc=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is_imported_fim\n",
      "False    106442\n",
      "True      19065\n",
      "Name: count, dtype: int64\n",
      "is_imported_fim\n",
      "False    9998\n",
      "True     2281\n",
      "Name: count, dtype: int64\n",
      "0.09783518050786012\n"
     ]
    }
   ],
   "source": [
    "df = ds.to_pandas()\n",
    "df[\"imported_fim_or_builtin\"] = df[\"is_builtin\"] | df[\"is_imported_fim\"]\n",
    "df[\"imported_fim_and_builtin\"] = df[\"is_builtin\"] & df[\"is_imported_fim\"]\n",
    "df_correct = df[df[\"correct\"]]\n",
    "df_incorrect = df[~df[\"correct\"]]\n",
    "print(df[\"is_imported_fim\"].value_counts())\n",
    "print((df_correct[\"is_imported_fim\"]).value_counts())\n",
    "print(df[\"correct\"].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.18576431305480903\n",
      "0.7217200097727828\n",
      "is_imported_fim\n",
      "False    9998\n",
      "True     2281\n",
      "Name: count, dtype: int64\n",
      "is_builtin\n",
      "True     8862\n",
      "False    3417\n",
      "Name: count, dtype: int64\n",
      "imported_fim_or_builtin\n",
      "True     11138\n",
      "False     1141\n",
      "Name: count, dtype: int64\n",
      "imported_fim_and_builtin\n",
      "False    12274\n",
      "True         5\n",
      "Name: count, dtype: int64\n",
      "0.20479439755790985\n",
      "0.7956545160711079\n",
      "0.9070771235442625\n",
      "fim_type\n",
      "bool    3\n",
      "int     2\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def ignore_types(d, types):\n",
    "    for t in types:\n",
    "        d = d[d[\"fim_type\"] != str(t)]\n",
    "    return d.reset_index()\n",
    " \n",
    "df_corr_imported = df_correct[df_correct[\"is_imported_fim\"]].reset_index()\n",
    "df_incorr_imported = df_incorrect[df_incorrect[\"is_imported_fim\"]].reset_index()\n",
    "# df_ic = ignore_types(df_, dir(builtins))\n",
    "# k=2\n",
    "# print(df_ic[\"fim_program\"][k], df_ic[\"fim_type\"][k], df_ic[\"is_imported_fim\"][k])\n",
    "\n",
    "# with pd.option_context('display.max_rows', None):\n",
    "#     print(df_ic[\"fim_type\"].value_counts())\n",
    "\n",
    "print(df_correct[\"is_imported_fim\"].mean())\n",
    "print(df_correct[\"is_builtin\"].mean())\n",
    "\n",
    "print(df_correct[\"is_imported_fim\"].value_counts())\n",
    "print(df_correct[\"is_builtin\"].value_counts())\n",
    "print(df_correct[\"imported_fim_or_builtin\"].value_counts())\n",
    "print(df_correct[\"imported_fim_and_builtin\"].value_counts())\n",
    "\n",
    "print(df_correct[\"is_imported_fim\"].sum() / df_correct[\"imported_fim_or_builtin\"].sum())\n",
    "print(df_correct[\"is_builtin\"].sum() / df_correct[\"imported_fim_or_builtin\"].sum())\n",
    "print(df_correct[\"imported_fim_or_builtin\"].mean())\n",
    "\n",
    "print(df_correct[df_correct[\"imported_fim_and_builtin\"]][\"fim_type\"].value_counts())\n",
    "item = df_correct[df_correct[\"imported_fim_and_builtin\"]].reset_index()\n",
    "# print(item[\"fim_program\"][0], item[\"fim_type\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "muts = pd.read_csv(f\"{DIR}/experiments/codellama_7b/nov7_test_all_v2_incorrect_log.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(nan, '\\n', 'float')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k=67\n",
    "muts[\"generated_text\"][k],muts[\"mutated_generated_text\"][k],muts[\"fim_type\"][k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mutated_generated_text\n",
       "\\n    1353\n",
       "\"\"      21\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "muts[\"mutated_generated_text\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "generated_text\n",
       "            109052\n",
       "\"\"            2164\n",
       "#              314\n",
       "\"\"\"            229\n",
       "~~~~~~~~       168\n",
       "             ...  \n",
       "any              1\n",
       "subset           1\n",
       "tp               1\n",
       "sound            1\n",
       "Se               1\n",
       "Name: count, Length: 211, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_incorrect[\"generated_text\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.09783518050786012, 125507)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"correct\"].mean(), df[\"correct\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/ssd/franlucc/envs/interp/lib/python3.10/site-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n",
      "You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36110fc5406e4d7e8b7781c98ec9b4de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "model_name=\"/home/arjun/models/CodeLlama-7b-hf\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    attn_implementation=\"flash_attention_2\"\n",
    ").to(\"cuda:0\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'key': 'archives/sara0871_desktop.zip/homeassistant/components/bmw_connected_drive/__init__.py',\n",
       " 'prefix': '\"\"\"\\nReads vehicle status from BMW connected drive portal.\\n\\nFor more details about this platform, please refer to the documentation at\\nhttps://home-assistant.io/components/bmw_connected_drive/\\n\"\"\"\\nimport datetime\\nimport logging\\n\\nimport voluptuous as vol\\n\\nfrom homeassistant.const import CONF_USERNAME, CONF_PASSWORD\\nfrom homeassistant.helpers import discovery\\nfrom homeassistant.helpers.event import track_utc_time_change\\nimport homeassistant.helpers.config_validation as cv\\n\\nREQUIREMENTS = [\\'bimmer_connected==0.5.1\\']\\n\\n_LOGGER = logging.getLogger(__name__)\\n\\nDOMAIN = \\'bmw_connected_drive\\'\\nCONF_REGION = \\'region\\'\\nATTR_VIN = \\'vin\\'\\n\\nACCOUNT_SCHEMA = vol.Schema({\\n    vol.Required(CONF_USERNAME): cv.string,\\n    vol.Required(CONF_PASSWORD): cv.string,\\n    vol.Required(CONF_REGION): vol.Any(\\'north_america\\', \\'china\\',\\n                                       \\'rest_of_world\\'),\\n})\\n\\nCONFIG_SCHEMA = vol.Schema({\\n    DOMAIN: {\\n        cv.string: ACCOUNT_SCHEMA\\n    },\\n}, extra=vol.ALLOW_EXTRA)\\n\\nSERVICE_SCHEMA = vol.Schema({\\n    vol.Required(ATTR_VIN): cv.string,\\n})\\n\\n\\nBMW_COMPONENTS = [\\'binary_sensor\\', \\'device_tracker\\', \\'lock\\', \\'sensor\\']\\nUPDATE_INTERVAL = 5  # in minutes\\n\\nSERVICE_UPDATE_STATE = \\'update_state\\'\\n\\n_SERVICE_MAP = {\\n    \\'light_flash\\': \\'trigger_remote_light_flash\\',\\n    \\'sound_horn\\': \\'trigger_remote_horn\\',\\n    \\'activate_air_conditioning\\': \\'trigger_remote_air_conditioning\\',\\n}\\n\\n\\ndef setup(hass, config: dict):\\n    \"\"\"Set up the BMW connected drive components.\"\"\"\\n    accounts = []\\n    for name, account_config in config[DOMAIN].items():\\n        accounts.append(setup_account(account_config, hass, name))\\n\\n    hass.data[DOMAIN] = accounts\\n\\n    def _update_all(call) -> None:\\n        \"\"\"Update all BMW accounts.\"\"\"\\n        for cd_account in hass.data[DOMAIN]:\\n            cd_account.update()\\n\\n    # Service to manually trigger updates for all accounts.\\n    hass.services.register(DOMAIN, SERVICE_UPDATE_STATE, _update_all)\\n\\n    _update_all(None)\\n\\n    for component in BMW_COMPONENTS:\\n        discovery.load_platform(hass, component, DOMAIN, {}, config)\\n\\n    return True\\n\\n\\ndef setup_account(account_config: dict, hass, name: str) \\\\\\n        -> \\'BMWConnectedDriveAccount\\':\\n    \"\"\"Set up a new BMWConnectedDriveAccount based on the config.\"\"\"\\n    username = account_config[CONF_USERNAME]\\n    password = account_config[CONF_PASSWORD]\\n    region = account_config[CONF_REGION]\\n    _LOGGER.debug(\\'Adding new account %s\\', name)\\n    cd_account = BMWConnectedDriveAccount(username, password, region, name)\\n\\n    def execute_service(call):\\n        \"\"\"Execute a service for a vehicle.\\n\\n        This must be a member function as we need access to the cd_account\\n        object here.\\n        \"\"\"\\n        vin = call.data[ATTR_VIN]\\n        vehicle = cd_account.account.get_vehicle(vin)\\n        if not vehicle:\\n            _LOGGER.error(\\'Could not find a vehicle for VIN \"%s\"!\\', vin)\\n            return\\n        function_name = _SERVICE_MAP[call.service]\\n        function_call = getattr(vehicle.remote_services, function_name)\\n        function_call()\\n\\n    # register the remote services\\n    for service in _SERVICE_MAP:\\n        hass.services.register(\\n            DOMAIN, service,\\n            execute_service,\\n            schema=SERVICE_SCHEMA)\\n\\n    # update every UPDATE_INTERVAL minutes, starting now\\n    # this should even out the load on the servers\\n    now = datetime.datetime.now()\\n    track_utc_time_change(\\n        hass, cd_account.update,\\n        minute=range(now.minute % UPDATE_INTERVAL, 60, UPDATE_INTERVAL),\\n        second=now.second)\\n\\n    return cd_account\\n\\n\\nclass BMWConnectedDriveAccount:\\n    \"\"\"Representation of a BMW vehicle.\"\"\"\\n\\n    def __init__(self, username: ',\n",
       " 'suffix': ', password: str, region_str: str,\\n                 name: str) -> None:\\n        \"\"\"Constructor.\"\"\"\\n        from bimmer_connected.account import ConnectedDriveAccount\\n        from bimmer_connected.country_selector import get_region_from_name\\n\\n        region = get_region_from_name(region_str)\\n\\n        self.account = ConnectedDriveAccount(username, password, region)\\n        self.name = name\\n        self._update_listeners = []\\n\\n    def update(self, *_):\\n        \"\"\"Update the state of all vehicles.\\n\\n        Notify all listeners about the update.\\n        \"\"\"\\n        _LOGGER.debug(\\'Updating vehicle state for account %s, \\'\\n                      \\'notifying %d listeners\\',\\n                      self.name, len(self._update_listeners))\\n        try:\\n            self.account.update_vehicle_states()\\n            for listener in self._update_listeners:\\n                listener()\\n        except IOError as exception:\\n            _LOGGER.error(\\'Error updating the vehicle state.\\')\\n            _LOGGER.exception(exception)\\n\\n    def add_update_listener(self, listener):\\n        \"\"\"Add a listener for update notifications.\"\"\"\\n        self._update_listeners.append(listener)\\n',\n",
       " 'middle': 'str',\n",
       " 'correct': False,\n",
       " 'model': 'CodeLlama-7b-hf',\n",
       " 'fim_type': 'str',\n",
       " 'fim_program': '\"\"\"\\nReads vehicle status from BMW connected drive portal.\\n\\nFor more details about this platform, please refer to the documentation at\\nhttps://home-assistant.io/components/bmw_connected_drive/\\n\"\"\"\\nimport datetime\\nimport logging\\n\\nimport voluptuous as vol\\n\\nfrom homeassistant.const import CONF_USERNAME, CONF_PASSWORD\\nfrom homeassistant.helpers import discovery\\nfrom homeassistant.helpers.event import track_utc_time_change\\nimport homeassistant.helpers.config_validation as cv\\n\\nREQUIREMENTS = [\\'bimmer_connected==0.5.1\\']\\n\\n_LOGGER = logging.getLogger(__name__)\\n\\nDOMAIN = \\'bmw_connected_drive\\'\\nCONF_REGION = \\'region\\'\\nATTR_VIN = \\'vin\\'\\n\\nACCOUNT_SCHEMA = vol.Schema({\\n    vol.Required(CONF_USERNAME): cv.string,\\n    vol.Required(CONF_PASSWORD): cv.string,\\n    vol.Required(CONF_REGION): vol.Any(\\'north_america\\', \\'china\\',\\n                                       \\'rest_of_world\\'),\\n})\\n\\nCONFIG_SCHEMA = vol.Schema({\\n    DOMAIN: {\\n        cv.string: ACCOUNT_SCHEMA\\n    },\\n}, extra=vol.ALLOW_EXTRA)\\n\\nSERVICE_SCHEMA = vol.Schema({\\n    vol.Required(ATTR_VIN): cv.string,\\n})\\n\\n\\nBMW_COMPONENTS = [\\'binary_sensor\\', \\'device_tracker\\', \\'lock\\', \\'sensor\\']\\nUPDATE_INTERVAL = 5  # in minutes\\n\\nSERVICE_UPDATE_STATE = \\'update_state\\'\\n\\n_SERVICE_MAP = {\\n    \\'light_flash\\': \\'trigger_remote_light_flash\\',\\n    \\'sound_horn\\': \\'trigger_remote_horn\\',\\n    \\'activate_air_conditioning\\': \\'trigger_remote_air_conditioning\\',\\n}\\n\\n\\ndef setup(hass, config: dict):\\n    \"\"\"Set up the BMW connected drive components.\"\"\"\\n    accounts = []\\n    for name, account_config in config[DOMAIN].items():\\n        accounts.append(setup_account(account_config, hass, name))\\n\\n    hass.data[DOMAIN] = accounts\\n\\n    def _update_all(call) -> None:\\n        \"\"\"Update all BMW accounts.\"\"\"\\n        for cd_account in hass.data[DOMAIN]:\\n            cd_account.update()\\n\\n    # Service to manually trigger updates for all accounts.\\n    hass.services.register(DOMAIN, SERVICE_UPDATE_STATE, _update_all)\\n\\n    _update_all(None)\\n\\n    for component in BMW_COMPONENTS:\\n        discovery.load_platform(hass, component, DOMAIN, {}, config)\\n\\n    return True\\n\\n\\ndef setup_account(account_config: dict, hass, name: str) \\\\\\n        -> \\'BMWConnectedDriveAccount\\':\\n    \"\"\"Set up a new BMWConnectedDriveAccount based on the config.\"\"\"\\n    username = account_config[CONF_USERNAME]\\n    password = account_config[CONF_PASSWORD]\\n    region = account_config[CONF_REGION]\\n    _LOGGER.debug(\\'Adding new account %s\\', name)\\n    cd_account = BMWConnectedDriveAccount(username, password, region, name)\\n\\n    def execute_service(call):\\n        \"\"\"Execute a service for a vehicle.\\n\\n        This must be a member function as we need access to the cd_account\\n        object here.\\n        \"\"\"\\n        vin = call.data[ATTR_VIN]\\n        vehicle = cd_account.account.get_vehicle(vin)\\n        if not vehicle:\\n            _LOGGER.error(\\'Could not find a vehicle for VIN \"%s\"!\\', vin)\\n            return\\n        function_name = _SERVICE_MAP[call.service]\\n        function_call = getattr(vehicle.remote_services, function_name)\\n        function_call()\\n\\n    # register the remote services\\n    for service in _SERVICE_MAP:\\n        hass.services.register(\\n            DOMAIN, service,\\n            execute_service,\\n            schema=SERVICE_SCHEMA)\\n\\n    # update every UPDATE_INTERVAL minutes, starting now\\n    # this should even out the load on the servers\\n    now = datetime.datetime.now()\\n    track_utc_time_change(\\n        hass, cd_account.update,\\n        minute=range(now.minute % UPDATE_INTERVAL, 60, UPDATE_INTERVAL),\\n        second=now.second)\\n\\n    return cd_account\\n\\n\\nclass BMWConnectedDriveAccount:\\n    \"\"\"Representation of a BMW vehicle.\"\"\"\\n\\n    def __init__(self, username: <FILL>, password: str, region_str: str,\\n                 name: str) -> None:\\n        \"\"\"Constructor.\"\"\"\\n        from bimmer_connected.account import ConnectedDriveAccount\\n        from bimmer_connected.country_selector import get_region_from_name\\n\\n        region = get_region_from_name(region_str)\\n\\n        self.account = ConnectedDriveAccount(username, password, region)\\n        self.name = name\\n        self._update_listeners = []\\n\\n    def update(self, *_):\\n        \"\"\"Update the state of all vehicles.\\n\\n        Notify all listeners about the update.\\n        \"\"\"\\n        _LOGGER.debug(\\'Updating vehicle state for account %s, \\'\\n                      \\'notifying %d listeners\\',\\n                      self.name, len(self._update_listeners))\\n        try:\\n            self.account.update_vehicle_states()\\n            for listener in self._update_listeners:\\n                listener()\\n        except IOError as exception:\\n            _LOGGER.error(\\'Error updating the vehicle state.\\')\\n            _LOGGER.exception(exception)\\n\\n    def add_update_listener(self, listener):\\n        \"\"\"Add a listener for update notifications.\"\"\"\\n        self._update_listeners.append(listener)\\n',\n",
       " 'hexsha': 'archives/sara0871_desktop.zip/homeassistant/components/bmw_connected_drive/__init__.py',\n",
       " 'generated_text': ''}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datasets\n",
    "\n",
    "def decode(outputs):\n",
    "    logits = torch.softmax(outputs.logits, dim=-1)\n",
    "    return torch.argmax(logits)\n",
    "\n",
    "def generate(model, prompt, tokenizer):\n",
    "    input_ids = tokenizer(prompt, return_tensors=\"pt\")[\"input_ids\"].to(model.device)\n",
    "    print(input_ids)\n",
    "    outputs = decode(model.forward(input_ids))\n",
    "    return tokenizer.decode(outputs)\n",
    "\n",
    "def codellama_fim_generate(model, prefix, suffix, tokenizer):\n",
    "    prefix_token_id = torch.tensor([[32007]])\n",
    "    suffix_token_id = torch.tensor([[32008]])\n",
    "    mid_token_id = torch.tensor([[32009]])\n",
    "    eos_token_id = torch.tensor([[32010]])\n",
    "    prefix = tokenizer(prefix, return_tensors=\"pt\", add_special_tokens=False)[\"input_ids\"]\n",
    "    suffix = tokenizer(suffix, return_tensors=\"pt\", add_special_tokens=False)[\"input_ids\"]\n",
    "    input_ids = torch.concatenate([prefix_token_id, prefix, suffix_token_id, suffix,mid_token_id, eos_token_id], dim=-1)\n",
    "    print(input_ids)\n",
    "    outputs = decode(model.forward(input_ids.to(model.device)))\n",
    "    return tokenizer.decode(outputs)\n",
    "\n",
    "ds = datasets.load_from_disk(f\"{EXPDIR}/experiments/codellama_7b/py_completions\")\n",
    "df = ds.to_pandas()\n",
    "ds_incorrect = df[~df[\"correct\"]].to_dict(orient=\"records\")\n",
    "ds_incorrect[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    1, 32007, 29937,  ..., 29897,    13, 32009]], device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('', 'str', '')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from codetrace.parsing_utils import get_model_fim, placeholder_to_std_fmt\n",
    "fim_obj = get_model_fim(model_name)\n",
    "item = ds_incorrect[-10]\n",
    "prompt = placeholder_to_std_fmt(item[\"fim_program\"], fim_obj)\n",
    "generated = generate(model, prompt, tokenizer)\n",
    "# print(item[\"fim_program\"])\n",
    "generated, item[\"fim_type\"], item[\"generated_text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[32007,   396, 14187,  ...,    13, 32009, 32010]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('', 'str', '')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated = codellama_fim_generate(model, item[\"prefix\"], item[\"suffix\"], tokenizer)\n",
    "generated, item[\"fim_type\"], item[\"generated_text\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deepseek completions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['key', 'prefix', 'suffix', 'middle', 'correct', 'model', 'fim_type', 'fim_program', 'hexsha'],\n",
       "        num_rows: 265879\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "py_data = datasets.load_dataset(\"nuprl-staging/py_typeinf_fim\")\n",
    "py_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _filter_not_imported_or_builtin(x):\n",
    "    try:\n",
    "        res = (not is_builtin(x[\"fim_type\"]) and not is_imported_ts(x[\"fim_type\"], x[\"fim_program\"]))\n",
    "    except:\n",
    "        res=False\n",
    "    return res\n",
    "\n",
    "ds_annotated = py_data.filter(_filter_not_imported_or_builtin,num_proc=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['key', 'prefix', 'suffix', 'middle', 'correct', 'model', 'fim_type', 'fim_program', 'hexsha'],\n",
       "        num_rows: 77190\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_annotated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BootableService\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating parquet from Arrow format: 100%|██████████| 39/39 [00:02<00:00, 14.13ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 39/39 [00:02<00:00, 14.70ba/s]\n",
      "Uploading the dataset shards: 100%|██████████| 2/2 [00:05<00:00,  2.94s/it]\n",
      "No files have been modified since last commit. Skipping to prevent empty commit.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/franlucc/py_typeinf_fim_user-defined-types/commit/7bf9fdd87d4b41f0bbf22a552985cfac7ef08947', commit_message='Upload dataset', commit_description='', oid='7bf9fdd87d4b41f0bbf22a552985cfac7ef08947', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(ds_annotated[\"train\"][30][\"fim_type\"])\n",
    "ds_annotated.push_to_hub(\"franlucc/py_typeinf_fim_user-defined-types\", private=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unrecognized keys in `rope_scaling` for 'rope_type'='linear': {'type'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 11-08 18:00:52 arg_utils.py:766] Chunked prefill is enabled by default for models with max_model_len > 32K. Currently, chunked prefill might not work with some features or models. If you encounter any issues, please disable chunked prefill by setting --enable-chunked-prefill=False.\n",
      "INFO 11-08 18:00:52 config.py:820] Chunked prefill is enabled with max_num_batched_tokens=512.\n",
      "INFO 11-08 18:00:52 llm_engine.py:174] Initializing an LLM engine (v0.5.4) with config: model='/mnt/ssd/franlucc/models/deepseek-coder-6.7b-base', speculative_config=None, tokenizer='/mnt/ssd/franlucc/models/deepseek-coder-6.7b-base', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=65536, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None), seed=0, served_model_name=/mnt/ssd/franlucc/models/deepseek-coder-6.7b-base, use_v2_block_manager=False, enable_prefix_caching=False)\n",
      "INFO 11-08 18:01:08 model_runner.py:720] Starting to load model /mnt/ssd/franlucc/models/deepseek-coder-6.7b-base...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]\n",
      "Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  1.98it/s]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.08s/it]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.01it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 11-08 18:01:10 model_runner.py:732] Loading model weights took 12.5708 GB\n",
      "INFO 11-08 18:01:11 gpu_executor.py:102] # GPU blocks: 7446, # CPU blocks: 512\n",
      "INFO 11-08 18:01:12 model_runner.py:1024] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.\n",
      "INFO 11-08 18:01:12 model_runner.py:1028] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\n",
      "INFO 11-08 18:01:22 model_runner.py:1225] Graph capturing finished in 10 secs.\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "model_name = \"/mnt/ssd/franlucc/models/deepseek-coder-6.7b-base\"\n",
    "# model = LLM(model_name, device=\"cuda\")\n",
    "model = AsyncLLMEngine.from_engine_args(\n",
    "    AsyncEngineArgs(model_name)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(llm: LLM, prompts:List[str])->List[str]:\n",
    "    params = SamplingParams(max_tokens=1, temperature=0, n=1)\n",
    "    outputs = llm.generate(prompts, sampling_params=params, request_id=0)\n",
    "    res =[]\n",
    "    for req_output in outputs:\n",
    "        for output in req_output.outputs:\n",
    "            res.append(output.text)\n",
    "    return res\n",
    "\n",
    "async def async_generate(llm: LLM, prompts:List[str], request_id:int)->List[str]:\n",
    "    params = SamplingParams(max_tokens=1, temperature=0, n=1)\n",
    "    outputs = llm.generate(prompts, sampling_params=params, request_id=request_id)\n",
    "    res =[]\n",
    "    async for req_output in outputs:\n",
    "        for output in req_output.outputs:\n",
    "            if output.text != \"\" and output.text != None:\n",
    "                res.append(output.text)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "async_generate() missing 1 required positional argument: 'request_id'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'''\u001b[39m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124mdef factorial(n: <FILL>):\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124m    pass\u001b[39m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124m'''\u001b[39m\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m async_generate(model, placeholder_to_std_fmt(prompt, DEEPSEEK_FIM))\n",
      "\u001b[0;31mTypeError\u001b[0m: async_generate() missing 1 required positional argument: 'request_id'"
     ]
    }
   ],
   "source": [
    "prompt = '''\n",
    "def factorial(n: <FILL>):\n",
    "    pass\n",
    "'''.strip()\n",
    "\n",
    "await async_generate(model, placeholder_to_std_fmt(prompt, DEEPSEEK_FIM))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mutated program + deepseek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = '''\"\"\"Fixtures for the lock entity platform tests.\"\"\"\n",
    "\n",
    "from collections.abc import Generator\n",
    "from typing import Any\n",
    "from unittest.mock import MagicMock\n",
    "\n",
    "import pytest\n",
    "\n",
    "from homeassistant.components.lock import (\n",
    "    DOMAIN as LOCK_DOMAIN,\n",
    "    LockEntity,\n",
    "    LockEntityFeature,\n",
    ")\n",
    "from homeassistant.config_entries import ConfigEntry, ConfigFlow\n",
    "from homeassistant.core import HomeAssistant\n",
    "from homeassistant.helpers import entity_registry as er\n",
    "from homeassistant.helpers.entity_platform import AddEntitiesCallback\n",
    "\n",
    "from tests.common import (\n",
    "    MockConfigEntry,\n",
    "    MockModule,\n",
    "    MockPlatform,\n",
    "    mock_config_flow,\n",
    "    mock_integration,\n",
    "    mock_platform,\n",
    ")\n",
    "from typing import TypeAlias\n",
    "__typ0 : TypeAlias = LockEntityFeature\n",
    "\n",
    "\n",
    "\n",
    "TEST_DOMAIN = \"test\"\n",
    "\n",
    "\n",
    "class MockLock(LockEntity):\n",
    "    \"\"\"Mocked lock entity.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        supported_features: __typ0 = __typ0(0),\n",
    "        code_format: str | None = None,\n",
    "    ) -> None:\n",
    "        \"\"\"Initialize the lock.\"\"\"\n",
    "        self.calls_open = MagicMock()\n",
    "        self.calls_lock = MagicMock()\n",
    "        self.calls_unlock = MagicMock()\n",
    "        self._attr_code_format = code_format\n",
    "        self._attr_supported_features = supported_features\n",
    "        self._attr_has_entity_name = True\n",
    "        self._attr_name = \"test_lock\"\n",
    "        self._attr_unique_id = \"very_unique_lock_id\"\n",
    "        super().__init__()\n",
    "\n",
    "    def lock(self, **kwargs: <FILL>) -> None:\n",
    "        \"\"\"Mock lock lock calls.\"\"\"\n",
    "        self.calls_lock(**kwargs)\n",
    "\n",
    "    def unlock(self, **kwargs: Any) -> None:\n",
    "        \"\"\"Mock lock unlock calls.\"\"\"\n",
    "        self.calls_unlock(**kwargs)\n",
    "\n",
    "    def open(self, **kwargs: Any) -> None:\n",
    "        \"\"\"Mock lock open calls.\"\"\"\n",
    "        self.calls_open(**kwargs)\n",
    "\n",
    "\n",
    "class MockFlow(ConfigFlow):\n",
    "    \"\"\"Test flow.\"\"\"\n",
    "\n",
    "\n",
    "@pytest.fixture(autouse=True)\n",
    "def config_flow_fixture(hass: HomeAssistant) -> Generator[None, None, None]:\n",
    "    \"\"\"Mock config flow.\"\"\"\n",
    "    mock_platform(hass, f\"{TEST_DOMAIN}.config_flow\")\n",
    "\n",
    "    with mock_config_flow(TEST_DOMAIN, MockFlow):\n",
    "        yield\n",
    "\n",
    "\n",
    "@pytest.fixture\n",
    "async def code_format() -> str | None:\n",
    "    \"\"\"Return the code format for the test lock entity.\"\"\"\n",
    "    return None\n",
    "\n",
    "\n",
    "@pytest.fixture(name=\"supported_features\")\n",
    "async def lock_supported_features() -> __typ0:\n",
    "    \"\"\"Return the supported features for the test lock entity.\"\"\"\n",
    "    return __typ0.OPEN\n",
    "\n",
    "\n",
    "@pytest.fixture(name=\"mock_lock_entity\")\n",
    "async def setup_lock_platform_test_entity(\n",
    "    hass: HomeAssistant,\n",
    "    entity_registry: er.EntityRegistry,\n",
    "    code_format: str | None,\n",
    "    supported_features: __typ0,\n",
    ") -> MagicMock:\n",
    "    \"\"\"Set up lock entity using an entity platform.\"\"\"\n",
    "\n",
    "    async def async_setup_entry_init(\n",
    "        hass: HomeAssistant, config_entry: ConfigEntry\n",
    "    ) -> bool:\n",
    "        \"\"\"Set up test config entry.\"\"\"\n",
    "        await hass.config_entries.async_forward_entry_setup(config_entry, LOCK_DOMAIN)\n",
    "        return True\n",
    "\n",
    "    MockPlatform(hass, f\"{TEST_DOMAIN}.config_flow\")\n",
    "    mock_integration(\n",
    "        hass,\n",
    "        MockModule(\n",
    "            TEST_DOMAIN,\n",
    "            async_setup_entry=async_setup_entry_init,\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    # Unnamed sensor without device class -> no name\n",
    "    entity = MockLock(\n",
    "        supported_features=supported_features,\n",
    "        code_format=code_format,\n",
    "    )\n",
    "\n",
    "    async def async_setup_entry_platform(\n",
    "        hass: HomeAssistant,\n",
    "        config_entry: ConfigEntry,\n",
    "        async_add_entities: AddEntitiesCallback,\n",
    "    ) -> None:\n",
    "        \"\"\"Set up test lock platform via config entry.\"\"\"\n",
    "        async_add_entities([entity])\n",
    "\n",
    "    mock_platform(\n",
    "        hass,\n",
    "        f\"{TEST_DOMAIN}.{LOCK_DOMAIN}\",\n",
    "        MockPlatform(async_setup_entry=async_setup_entry_platform),\n",
    "    )\n",
    "\n",
    "    config_entry = MockConfigEntry(domain=TEST_DOMAIN)\n",
    "    config_entry.add_to_hass(hass)\n",
    "    assert await hass.config_entries.async_setup(config_entry.entry_id)\n",
    "    await hass.async_block_till_done()\n",
    "\n",
    "    state = hass.states.get(entity.entity_id)\n",
    "    assert state is not None\n",
    "\n",
    "    return entity'''.strip()\n",
    "\n",
    "original = '''\n",
    "\"\"\"Fixtures for the lock entity platform tests.\"\"\"\n",
    "\n",
    "from collections.abc import Generator\n",
    "from typing import Any\n",
    "from unittest.mock import MagicMock\n",
    "\n",
    "import pytest\n",
    "\n",
    "from homeassistant.components.lock import (\n",
    "    DOMAIN as LOCK_DOMAIN,\n",
    "    LockEntity,\n",
    "    LockEntityFeature,\n",
    ")\n",
    "from homeassistant.config_entries import ConfigEntry, ConfigFlow\n",
    "from homeassistant.core import HomeAssistant\n",
    "from homeassistant.helpers import entity_registry as er\n",
    "from homeassistant.helpers.entity_platform import AddEntitiesCallback\n",
    "\n",
    "from tests.common import (\n",
    "    MockConfigEntry,\n",
    "    MockModule,\n",
    "    MockPlatform,\n",
    "    mock_config_flow,\n",
    "    mock_integration,\n",
    "    mock_platform,\n",
    ")\n",
    "\n",
    "TEST_DOMAIN = \"test\"\n",
    "\n",
    "\n",
    "class MockLock(LockEntity):\n",
    "    \"\"\"Mocked lock entity.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        supported_features: LockEntityFeature = LockEntityFeature(0),\n",
    "        code_format: str | None = None,\n",
    "    ) -> None:\n",
    "        \"\"\"Initialize the lock.\"\"\"\n",
    "        self.calls_open = MagicMock()\n",
    "        self.calls_lock = MagicMock()\n",
    "        self.calls_unlock = MagicMock()\n",
    "        self._attr_code_format = code_format\n",
    "        self._attr_supported_features = supported_features\n",
    "        self._attr_has_entity_name = True\n",
    "        self._attr_name = \"test_lock\"\n",
    "        self._attr_unique_id = \"very_unique_lock_id\"\n",
    "        super().__init__()\n",
    "\n",
    "    def lock(self, **kwargs: <FILL>) -> None:\n",
    "        \"\"\"Mock lock lock calls.\"\"\"\n",
    "        self.calls_lock(**kwargs)\n",
    "\n",
    "    def unlock(self, **kwargs: Any) -> None:\n",
    "        \"\"\"Mock lock unlock calls.\"\"\"\n",
    "        self.calls_unlock(**kwargs)\n",
    "\n",
    "    def open(self, **kwargs: Any) -> None:\n",
    "        \"\"\"Mock lock open calls.\"\"\"\n",
    "        self.calls_open(**kwargs)\n",
    "\n",
    "\n",
    "class MockFlow(ConfigFlow):\n",
    "    \"\"\"Test flow.\"\"\"\n",
    "\n",
    "\n",
    "@pytest.fixture(autouse=True)\n",
    "def config_flow_fixture(hass: HomeAssistant) -> Generator[None, None, None]:\n",
    "    \"\"\"Mock config flow.\"\"\"\n",
    "    mock_platform(hass, f\"{TEST_DOMAIN}.config_flow\")\n",
    "\n",
    "    with mock_config_flow(TEST_DOMAIN, MockFlow):\n",
    "        yield\n",
    "\n",
    "\n",
    "@pytest.fixture\n",
    "async def code_format() -> str | None:\n",
    "    \"\"\"Return the code format for the test lock entity.\"\"\"\n",
    "    return None\n",
    "\n",
    "\n",
    "@pytest.fixture(name=\"supported_features\")\n",
    "async def lock_supported_features() -> LockEntityFeature:\n",
    "    \"\"\"Return the supported features for the test lock entity.\"\"\"\n",
    "    return LockEntityFeature.OPEN\n",
    "\n",
    "\n",
    "@pytest.fixture(name=\"mock_lock_entity\")\n",
    "async def setup_lock_platform_test_entity(\n",
    "    hass: HomeAssistant,\n",
    "    entity_registry: er.EntityRegistry,\n",
    "    code_format: str | None,\n",
    "    supported_features: LockEntityFeature,\n",
    ") -> MagicMock:\n",
    "    \"\"\"Set up lock entity using an entity platform.\"\"\"\n",
    "\n",
    "    async def async_setup_entry_init(\n",
    "        hass: HomeAssistant, config_entry: ConfigEntry\n",
    "    ) -> bool:\n",
    "        \"\"\"Set up test config entry.\"\"\"\n",
    "        await hass.config_entries.async_forward_entry_setup(config_entry, LOCK_DOMAIN)\n",
    "        return True\n",
    "\n",
    "    MockPlatform(hass, f\"{TEST_DOMAIN}.config_flow\")\n",
    "    mock_integration(\n",
    "        hass,\n",
    "        MockModule(\n",
    "            TEST_DOMAIN,\n",
    "            async_setup_entry=async_setup_entry_init,\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    # Unnamed sensor without device class -> no name\n",
    "    entity = MockLock(\n",
    "        supported_features=supported_features,\n",
    "        code_format=code_format,\n",
    "    )\n",
    "\n",
    "    async def async_setup_entry_platform(\n",
    "        hass: HomeAssistant,\n",
    "        config_entry: ConfigEntry,\n",
    "        async_add_entities: AddEntitiesCallback,\n",
    "    ) -> None:\n",
    "        \"\"\"Set up test lock platform via config entry.\"\"\"\n",
    "        async_add_entities([entity])\n",
    "\n",
    "    mock_platform(\n",
    "        hass,\n",
    "        f\"{TEST_DOMAIN}.{LOCK_DOMAIN}\",\n",
    "        MockPlatform(async_setup_entry=async_setup_entry_platform),\n",
    "    )\n",
    "\n",
    "    config_entry = MockConfigEntry(domain=TEST_DOMAIN)\n",
    "    config_entry.add_to_hass(hass)\n",
    "    assert await hass.config_entries.async_setup(config_entry.entry_id)\n",
    "    await hass.async_block_till_done()\n",
    "\n",
    "    state = hass.states.get(entity.entity_id)\n",
    "    assert state is not None\n",
    "\n",
    "    return entity\n",
    "'''.strip()\n",
    "fim_type=\"Any\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 0 examples [00:00, ? examples/s]/home/franlucc/venvs/vllm/lib/python3.10/site-packages/datasets/download/streaming_download_manager.py:784: FutureWarning: The 'verbose' keyword in pd.read_csv is deprecated and will be removed in a future version.\n",
      "  return pd.read_csv(xopen(filepath_or_buffer, \"rb\", download_config=download_config), **kwargs)\n",
      "Generating train split: 45 examples [00:00, 3360.04 examples/s]\n"
     ]
    }
   ],
   "source": [
    "ds = load(f\"{DIR}/experiments/deepseek_7b_base/nov8_rename_types.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 11-08 15:41:39 async_llm_engine.py:174] Added request 3.\n",
      "INFO 11-08 15:41:39 async_llm_engine.py:174] Added request 4.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(['Any'], ['Any'])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# k = 0\n",
    "# original = ds[k][\"fim_program\"]\n",
    "# prompt = ds[k][\"mutated_program\"]\n",
    "# fim_type = ds[k][\"fim_type\"]\n",
    "\n",
    "original_answer = await async_generate(model, placeholder_to_std_fmt(original, DEEPSEEK_FIM),3)\n",
    "new_answer = await async_generate(model, placeholder_to_std_fmt(prompt, DEEPSEEK_FIM),4)\n",
    "original_answer, new_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Any']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "interp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
