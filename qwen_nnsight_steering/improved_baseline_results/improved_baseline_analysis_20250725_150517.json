{
  "baseline": {
    "overall_accuracy": 0.8333333333333334,
    "total_examples": 18,
    "correct_predictions": 15,
    "cwe_metrics": {
      "CWE-22": {
        "total": 3,
        "correct": 3,
        "reasoning_scores": [
          0.75,
          0.6666666666666666,
          0.5833333333333333
        ],
        "accuracy": 1.0,
        "avg_reasoning": 0.6666666666666666
      },
      "CWE-77": {
        "total": 3,
        "correct": 3,
        "reasoning_scores": [
          0.5,
          0.5416666666666666,
          0.20833333333333331
        ],
        "accuracy": 1.0,
        "avg_reasoning": 0.4166666666666666
      },
      "CWE-190": {
        "total": 3,
        "correct": 0,
        "reasoning_scores": [
          0.0,
          0.4583333333333333,
          0.08333333333333333
        ],
        "accuracy": 0.0,
        "avg_reasoning": 0.18055555555555555
      },
      "CWE-416": {
        "total": 3,
        "correct": 3,
        "reasoning_scores": [
          0.3333333333333333,
          0.41666666666666663,
          0.29166666666666663
        ],
        "accuracy": 1.0,
        "avg_reasoning": 0.34722222222222215
      },
      "CWE-476": {
        "total": 3,
        "correct": 3,
        "reasoning_scores": [
          0.29166666666666663,
          0.20833333333333331,
          0.4583333333333333
        ],
        "accuracy": 1.0,
        "avg_reasoning": 0.3194444444444444
      },
      "CWE-787": {
        "total": 3,
        "correct": 3,
        "reasoning_scores": [
          0.29166666666666663,
          0.41666666666666663,
          0.3333333333333333
        ],
        "accuracy": 1.0,
        "avg_reasoning": 0.34722222222222215
      }
    },
    "avg_reasoning_quality": 0.3796296296296296
  }
}