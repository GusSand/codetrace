392
278
Training...
Batch loss: 6.277932643890381
Batch loss: 1.2101045846939087
Batch loss: 6.260084629058838
Batch loss: 2.354928970336914
Batch loss: 1.1539186239242554
Batch loss: -0.4145490825176239
Batch loss: 31.072065353393555
Batch loss: -0.44360995292663574
Batch loss: 5.542983531951904
Batch loss: 4.487159252166748
Batch loss: 1.5469951629638672
Batch loss: 2.226962089538574
Batch loss: 6.028411388397217
Batch loss: 0.7433010935783386
Batch loss: 5.212251663208008
Batch loss: 13.41679573059082
Batch loss: 9.05448055267334
Batch loss: 0.9937096834182739
Batch loss: 0.2488945573568344
Batch loss: 2.3714733123779297
Batch loss: 0.841690719127655
Batch loss: 5.498485565185547
Batch loss: 0.49624869227409363
Batch loss: 1.0166107416152954
Batch loss: 0.8010530471801758
Batch loss: 1.7825138568878174
Batch loss: 1.2779121398925781
Batch loss: 0.15223602950572968
Batch loss: 7.517017364501953
Batch loss: 1.0306791067123413
Batch loss: 0.805414617061615
Batch loss: 2.9343113899230957
Batch loss: 0.9084586501121521
Batch loss: 3.95151686668396
Batch loss: 0.5340040326118469
Batch loss: 3.6834609508514404
Batch loss: 0.09777446836233139
Batch loss: 2.677236557006836
Batch loss: 2.5333220958709717
Batch loss: 0.6991658210754395
Batch loss: 3.854015827178955
Batch loss: 0.7231403589248657
Batch loss: 3.6629951000213623
Batch loss: 3.953057050704956
Batch loss: 17.871400833129883
Batch loss: 3.169271469116211
Batch loss: 29.942739486694336
Batch loss: 2.3086776733398438
Batch loss: 1.8428500890731812
Batch loss: 1.3312851190567017
Batch loss: 4.961185455322266
Batch loss: 16.442867279052734
Batch loss: 2.9237141609191895
Batch loss: 6.099756240844727
Batch loss: 11.557146072387695
Batch loss: 1.1555083990097046
Epoch: 1 	Training Loss: 4.471125
Batch loss: 6.277932643890381
Batch loss: 1.2101045846939087
Batch loss: 6.260084629058838
Batch loss: 2.354928970336914
Batch loss: 1.1539186239242554
Traceback (most recent call last):
  File "/home/franlucc/projects/codetrace/train.py", line 283, in <module>
    train_loop(llm)
  File "/home/franlucc/projects/codetrace/train.py", line 204, in train_loop
    causal_loss, _ = apply_mask(llm, output, prompts, correct_idxs, incorrect_idxs)
  File "/home/franlucc/projects/codetrace/train.py", line 80, in apply_mask
    with llm.generate(max_new_tokens=1,
  File "/home/franlucc/venvs/gpu/lib/python3.10/site-packages/nnsight/contexts/Runner.py", line 73, in __exit__
    self.run_local()
  File "/home/franlucc/venvs/gpu/lib/python3.10/site-packages/nnsight/contexts/Runner.py", line 78, in run_local
    self.output = self.model(
  File "/home/franlucc/venvs/gpu/lib/python3.10/site-packages/nnsight/models/NNsightModel.py", line 194, in __call__
    output = fn(inputs, *args, **kwargs)
  File "/home/franlucc/venvs/gpu/lib/python3.10/site-packages/nnsight/models/LanguageModel.py", line 166, in _generation
    return super()._generation(
  File "/home/franlucc/venvs/gpu/lib/python3.10/site-packages/nnsight/models/NNsightModel.py", line 412, in _generation
    return self.local_model.generate(
  File "/home/franlucc/venvs/gpu/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/home/franlucc/venvs/gpu/lib/python3.10/site-packages/transformers/generation/utils.py", line 1474, in generate
    return self.greedy_search(
  File "/home/franlucc/venvs/gpu/lib/python3.10/site-packages/transformers/generation/utils.py", line 2392, in greedy_search
    if unfinished_sequences.max() == 0:
KeyboardInterrupt