392
278
Training...
Model parameters before training:
conv1.weight: tensor([[[ 0.0901,  0.0978, -0.0276],
         [ 0.1083, -0.0258,  0.0238],
         [-0.0574,  0.0692,  0.1039],
         ...,
         [-0.0406,  0.0361, -0.0246],
         [ 0.0977, -0.0699, -0.0703],
         [-0.0703,  0.1060,  0.0393]],
        [[ 0.1134, -0.0973, -0.1169],
         [-0.0922, -0.0793,  0.0477],
         [ 0.0422,  0.0979, -0.0609],
         ...,
         [-0.0452, -0.0978, -0.1172],
         [ 0.0337, -0.0257,  0.0459],
         [-0.0967,  0.0875, -0.0865]],
        [[-0.0203,  0.0246,  0.0608],
         [ 0.0951,  0.1074, -0.0934],
         [ 0.0297, -0.0507, -0.0129],
         ...,
         [-0.1056, -0.0384,  0.0398],
         [ 0.0751,  0.0544, -0.1042],
         [-0.0709, -0.0186,  0.1140]],
        ...,
        [[-0.0612,  0.0476,  0.0200],
         [-0.0377, -0.0916, -0.0371],
         [-0.0497, -0.0384, -0.1063],
         ...,
         [-0.1109,  0.0541, -0.0535],
         [-0.0611,  0.0282, -0.0615],
         [-0.0545, -0.0397, -0.0443]],
        [[-0.0492, -0.0318,  0.0306],
         [-0.0954, -0.0713,  0.0017],
         [ 0.0164,  0.0651, -0.0828],
         ...,
         [ 0.0737,  0.0023,  0.0542],
         [-0.0422,  0.0513, -0.0379],
         [-0.0020, -0.1026, -0.0308]],
        [[-0.0620, -0.0398, -0.0753],
         [-0.1060,  0.0077,  0.0765],
         [ 0.1073,  0.0688, -0.0611],
         ...,
         [-0.0988,  0.0035, -0.0524],
         [-0.0579, -0.1079,  0.0625],
         [ 0.0227, -0.0996,  0.0935]]])
conv1.bias: tensor([ 0.0355,  0.0219, -0.0692,  0.0178,  0.1136,  0.0808, -0.0918,  0.1076,
         0.0091,  0.0567,  0.0915,  0.1005, -0.0919,  0.1032, -0.0800,  0.0088])
conv2.weight: tensor([[[-0.1009, -0.0316, -0.0066],
         [-0.0173, -0.0228,  0.0114],
         [ 0.1424,  0.0839,  0.0808],
         [ 0.0578,  0.1117, -0.0067],
         [ 0.0115,  0.0297, -0.1259],
         [-0.1163,  0.0177, -0.0565],
         [-0.0026, -0.0331,  0.0225],
         [ 0.0939, -0.0479,  0.1156],
         [ 0.1140, -0.1108, -0.1115],
         [-0.1168, -0.0791, -0.0562],
         [-0.0109, -0.0351, -0.0729],
         [-0.0459, -0.0522,  0.1416],
         [-0.0535, -0.1033,  0.0600],
         [-0.0083,  0.1105,  0.0902],
         [ 0.1326, -0.1057,  0.0928],
         [ 0.1211, -0.0713,  0.1327]],
        [[ 0.1082,  0.0016,  0.0696],
         [-0.0505, -0.1259,  0.0365],
         [ 0.0430, -0.0943,  0.0700],
         [-0.1233,  0.1242,  0.1398],
         [ 0.0393, -0.0906,  0.0702],
         [ 0.0246,  0.0392,  0.0474],
         [ 0.1099, -0.0620, -0.0325],
         [ 0.0394,  0.0157,  0.1164],
         [-0.0758, -0.0053,  0.0270],
         [-0.0383,  0.0984,  0.0158],
         [-0.1334, -0.0156, -0.0655],
         [ 0.0140, -0.0168, -0.1432],
         [-0.0263, -0.0138, -0.0426],
         [ 0.1326, -0.0315,  0.0927],
         [ 0.0358, -0.1218,  0.0339],
         [ 0.1196, -0.0944, -0.0933]],
        [[ 0.1413,  0.1160, -0.0805],
         [ 0.0869, -0.0185, -0.1423],
         [ 0.0108,  0.0466, -0.0433],
         [ 0.0502, -0.1234,  0.1000],
         [ 0.1231,  0.0796,  0.0245],
         [ 0.0475, -0.1044, -0.0361],
         [-0.0138, -0.0803, -0.1066],
         [ 0.0971,  0.0980, -0.1311],
         [ 0.0459,  0.0587,  0.1371],
         [ 0.0835,  0.1327, -0.0473],
         [ 0.1011,  0.1174, -0.1363],
         [-0.1159,  0.0292,  0.0788],
         [-0.0717,  0.0159, -0.0002],
         [ 0.0365, -0.0776,  0.0814],
         [ 0.0960, -0.1001,  0.0014],
         [ 0.0004,  0.0463,  0.1345]],
        [[ 0.0423, -0.0328,  0.1296],
         [-0.0549, -0.0419,  0.0099],
         [-0.1099,  0.0157, -0.0979],
         [ 0.0148,  0.0138,  0.0200],
         [-0.1217, -0.1371,  0.0664],
         [ 0.1238, -0.1281,  0.0535],
         [-0.1062,  0.0090,  0.1343],
         [ 0.1095, -0.1055,  0.0893],
         [ 0.0754, -0.0002,  0.1398],
         [-0.0573, -0.0336, -0.0730],
         [ 0.0208,  0.0382,  0.0115],
         [-0.0812, -0.0650,  0.0491],
         [-0.1266, -0.0225, -0.0032],
         [-0.0585,  0.0525,  0.0093],
         [ 0.1013, -0.0128, -0.0911],
         [ 0.1020,  0.0202, -0.0413]]])
conv2.bias: tensor([-0.0951,  0.0338, -0.1377,  0.0380])
t_conv1.weight: tensor([[[ 8.7406e-02, -1.5507e-01],
         [-1.1573e-01, -1.2709e-01],
         [ 1.4858e-01,  1.5028e-01],
         [ 1.1066e-02,  1.6596e-01],
         [-5.9097e-02, -1.7162e-01],
         [ 6.1747e-02,  6.2626e-02],
         [ 1.7331e-01, -5.1166e-05],
         [ 1.3548e-01,  1.0836e-01],
         [ 1.2795e-01, -1.7542e-01],
         [ 1.4557e-01, -1.5069e-01],
         [ 1.5848e-01, -7.3257e-03],
         [-1.5666e-01,  4.9160e-02],
         [-3.5982e-02, -1.5878e-01],
         [-6.4088e-02,  1.8227e-02],
         [ 1.3768e-01, -5.4346e-02],
         [ 1.0500e-01,  2.2137e-02]],
        [[ 5.9588e-03,  3.3825e-02],
         [-1.1601e-01, -1.4694e-01],
         [-5.5545e-02, -1.6473e-01],
         [-8.2440e-02,  8.1328e-03],
         [-1.1643e-01, -7.3326e-02],
         [-3.1764e-02, -2.0365e-02],
         [-9.7583e-02,  8.4943e-03],
         [-2.4812e-02,  5.0557e-02],
         [ 7.9846e-03, -8.8277e-02],
         [-6.0861e-02, -2.0375e-03],
         [-1.1031e-01,  1.3839e-02],
         [-1.2481e-02,  6.8586e-02],
         [ 4.1837e-02,  1.3230e-01],
         [-5.8275e-03, -1.3062e-01],
         [ 7.9021e-02, -1.1947e-01],
         [-2.4298e-02, -5.7241e-02]],
        [[-6.7077e-02, -6.5405e-02],
         [ 1.6244e-01,  1.0120e-01],
         [ 4.8991e-02,  1.6599e-01],
         [-1.6020e-01,  2.8526e-02],
         [ 1.1317e-01,  1.1743e-01],
         [-1.4069e-01,  6.2913e-02],
         [-1.0071e-01, -6.9073e-03],
         [-3.6888e-02, -1.4760e-01],
         [-1.6863e-01, -1.1630e-01],
         [ 8.0216e-02,  8.0864e-02],
         [-1.5375e-01, -6.6387e-02],
         [ 2.8875e-03, -1.5284e-01],
         [ 9.9606e-02,  1.6011e-01],
         [ 3.1265e-02, -1.3135e-01],
         [ 4.1222e-02,  6.4172e-02],
         [ 1.3998e-01, -9.4058e-02]],
        [[-1.5838e-01,  7.7667e-02],
         [ 1.1005e-02, -5.7599e-02],
         [-7.4073e-02, -9.1149e-02],
         [ 1.4310e-01, -3.0501e-02],
         [ 1.2749e-01,  1.5780e-01],
         [ 2.2393e-02,  3.7657e-02],
         [-1.2039e-02,  1.2141e-01],
         [-1.5929e-01,  7.0301e-02],
         [-2.8802e-02,  8.0719e-02],
         [-7.8737e-04, -6.5454e-02],
         [-1.9083e-02,  9.5458e-02],
         [-1.2278e-01, -1.1174e-01],
         [-3.9597e-02, -6.4121e-02],
         [ 6.9445e-02,  1.1897e-01],
         [-1.8933e-02,  1.6716e-01],
         [-7.3861e-02, -9.9200e-02]]])
t_conv1.bias: tensor([-0.0791, -0.1218, -0.1239, -0.1575, -0.1567,  0.0461,  0.1078,  0.1660,
         0.1506, -0.0102,  0.0343, -0.1058,  0.0683, -0.1695,  0.0834,  0.0324])
t_conv2.weight: tensor([[[ 0.0444,  0.0528],
         [-0.0663,  0.1239],
         [ 0.0689,  0.0948],
         [ 0.0191,  0.0906],
         [ 0.0971,  0.0654],
         [ 0.1100, -0.0262],
         [ 0.0949,  0.0333],
         [ 0.0868,  0.1406],
         [ 0.0327, -0.0536],
         [-0.0144,  0.0406],
         [ 0.0243, -0.0394],
         [ 0.1131,  0.0867],
         [-0.0897, -0.0118],
         [-0.0139, -0.0905],
         [ 0.0211, -0.0443],
         [-0.0745, -0.0464],
         [-0.0515,  0.1381],
         [ 0.0554,  0.1420],
         [ 0.0396,  0.0327],
         [ 0.0593,  0.0248],
         [-0.1133, -0.0854],
         [-0.0350,  0.0022],
         [ 0.0544,  0.0556],
         [ 0.1145,  0.0294]],
        [[-0.0493, -0.1085],
         [-0.1057, -0.0862],
         [ 0.0435,  0.0780],
         [ 0.1263, -0.0457],
         [-0.0114, -0.0429],
         [-0.0005,  0.0463],
         [-0.0032,  0.0067],
         [ 0.0183,  0.0538],
         [-0.0438, -0.0861],
         [ 0.0341, -0.0171],
         [-0.0654,  0.0606],
         [ 0.0013, -0.0210],
         [-0.0699, -0.0190],
         [-0.1227,  0.0328],
         [ 0.0022,  0.0876],
         [ 0.0093,  0.0115],
         [ 0.0393,  0.1098],
         [-0.0682,  0.0862],
         [ 0.0353, -0.0963],
         [ 0.0503, -0.0866],
         [-0.0454, -0.0688],
         [-0.0982,  0.1137],
         [-0.1290,  0.0722],
         [-0.1299, -0.0176]],
        [[ 0.0086,  0.1026],
         [-0.0522,  0.0415],
         [ 0.0224,  0.0849],
         [ 0.0086,  0.0540],
         [-0.0872, -0.1003],
         [ 0.1286, -0.1052],
         [-0.0246, -0.0174],
         [ 0.1411, -0.0312],
         [-0.1099, -0.0366],
         [ 0.0745,  0.0572],
         [ 0.1194, -0.0295],
         [ 0.0680, -0.1358],
         [ 0.0558,  0.0663],
         [ 0.0931, -0.0828],
         [-0.0385,  0.0349],
         [-0.1026, -0.1148],
         [-0.1389,  0.0081],
         [ 0.0896,  0.0371],
         [ 0.0088,  0.0503],
         [-0.0907,  0.0152],
         [-0.0359, -0.0715],
         [ 0.1245, -0.1117],
         [ 0.0212, -0.1268],
         [-0.0049, -0.0641]],
        [[ 0.0475, -0.0811],
         [ 0.0924, -0.1171],
         [ 0.0867, -0.1084],
         [ 0.0773, -0.0608],
         [-0.0003, -0.0263],
         [ 0.0937,  0.0473],
         [-0.1272,  0.0133],
         [-0.0996,  0.1079],
         [ 0.0237, -0.0371],
         [-0.0736,  0.0500],
         [-0.0864,  0.0685],
         [ 0.0788,  0.0886],
         [ 0.0377, -0.1263],
         [ 0.1038, -0.0448],
         [-0.0427, -0.0155],
         [ 0.1055,  0.1110],
         [ 0.0223,  0.0689],
         [-0.1345,  0.0003],
         [-0.1277,  0.0491],
         [-0.1028, -0.0514],
         [ 0.1009,  0.1379],
         [-0.0867, -0.0801],
         [ 0.0179,  0.0567],
         [-0.0235, -0.0451]],
        [[-0.0948,  0.0616],
         [ 0.1414, -0.0699],
         [ 0.0681,  0.0705],
         [ 0.1160, -0.0164],
         [ 0.0045,  0.1060],
         [ 0.0912,  0.1426],
         [-0.0414,  0.0571],
         [ 0.1008, -0.0980],
         [ 0.0287, -0.0323],
         [ 0.0928, -0.0648],
         [ 0.0101,  0.0864],
         [-0.1322, -0.1219],
         [-0.0739,  0.0926],
         [ 0.0968, -0.0986],
         [ 0.0275, -0.0765],
         [-0.0670,  0.1245],
         [ 0.0697, -0.0395],
         [ 0.0212,  0.0280],
         [ 0.0338, -0.0494],
         [-0.0850,  0.0956],
         [ 0.0194,  0.0604],
         [-0.0547,  0.0699],
         [ 0.1050,  0.0878],
         [ 0.0392,  0.1420]],
        [[-0.0003,  0.0307],
         [ 0.1371,  0.1403],
         [-0.0609,  0.1300],
         [ 0.0533, -0.0162],
         [ 0.1260, -0.0748],
         [ 0.0938,  0.1430],
         [-0.0995, -0.0852],
         [-0.1430, -0.0260],
         [-0.1311, -0.0483],
         [ 0.0438,  0.1020],
         [ 0.0804,  0.0801],
         [ 0.0599, -0.0895],
         [-0.1146,  0.0060],
         [ 0.1371,  0.0081],
         [-0.0124, -0.0980],
         [-0.0716, -0.1113],
         [ 0.1156, -0.0235],
         [-0.1275,  0.0155],
         [ 0.0105, -0.0178],
         [ 0.0517,  0.0776],
         [-0.1357, -0.1106],
         [-0.0069, -0.1338],
         [-0.1311,  0.1274],
         [-0.0110, -0.0714]],
        [[-0.0495, -0.1127],
         [ 0.1126, -0.0313],
         [-0.0812, -0.1095],
         [ 0.0844, -0.0200],
         [-0.0152, -0.0376],
         [-0.0697,  0.0257],
         [ 0.1110, -0.0837],
         [ 0.0069, -0.1098],
         [-0.0677,  0.1267],
         [ 0.0015,  0.1390],
         [-0.0253, -0.0787],
         [-0.0862,  0.1279],
         [-0.1110,  0.0757],
         [ 0.0359,  0.0426],
         [ 0.0814, -0.0378],
         [ 0.0893, -0.1150],
         [-0.0508,  0.1057],
         [ 0.0428, -0.0192],
         [-0.0337, -0.0881],
         [ 0.0878, -0.0046],
         [-0.0049,  0.0341],
         [ 0.1065, -0.0736],
         [-0.0497,  0.0978],
         [ 0.0815, -0.0710]],
        [[-0.1428,  0.0268],
         [ 0.0759,  0.0345],
         [ 0.1024, -0.1145],
         [ 0.0728, -0.0897],
         [ 0.0812,  0.1073],
         [ 0.0457,  0.1168],
         [-0.0951, -0.1291],
         [-0.1388,  0.0906],
         [ 0.0506, -0.1057],
         [ 0.0699,  0.1317],
         [-0.1423,  0.1047],
         [ 0.0221,  0.0134],
         [ 0.1299,  0.1307],
         [ 0.0608,  0.1140],
         [ 0.0600,  0.0235],
         [-0.1269,  0.0270],
         [-0.1027,  0.0444],
         [ 0.0255,  0.0032],
         [-0.0987, -0.0875],
         [ 0.1067,  0.0703],
         [ 0.0761, -0.0430],
         [-0.0249, -0.0370],
         [ 0.0993, -0.0623],
         [ 0.0909,  0.0995]],
        [[-0.1320,  0.0009],
         [-0.0275, -0.0798],
         [ 0.0623, -0.0175],
         [ 0.1264, -0.0903],
         [ 0.0671, -0.1232],
         [-0.0723,  0.0098],
         [ 0.1140,  0.0760],
         [-0.1185,  0.0160],
         [-0.0851,  0.0063],
         [-0.1202, -0.0423],
         [ 0.0990, -0.1324],
         [-0.1376,  0.0263],
         [ 0.0198, -0.0264],
         [ 0.1260, -0.0869],
         [-0.0876, -0.1079],
         [-0.0269, -0.0368],
         [ 0.0893, -0.0081],
         [ 0.0461, -0.0600],
         [ 0.1171,  0.1217],
         [-0.1293, -0.0371],
         [-0.1225,  0.0613],
         [-0.1261, -0.0682],
         [ 0.1442, -0.1378],
         [ 0.1065,  0.0122]],
        [[ 0.1154, -0.0732],
         [ 0.0948,  0.0174],
         [ 0.0111,  0.0985],
         [-0.1372, -0.1163],
         [ 0.1394, -0.0867],
         [-0.1040, -0.0071],
         [-0.0462, -0.0197],
         [-0.0967,  0.0521],
         [-0.1242,  0.0117],
         [ 0.0842,  0.0277],
         [ 0.0192,  0.0211],
         [-0.0423, -0.0275],
         [-0.0609, -0.0975],
         [-0.0764,  0.1427],
         [-0.0242,  0.0506],
         [ 0.0998, -0.0113],
         [-0.0776, -0.0978],
         [-0.0532,  0.0515],
         [-0.1216, -0.0176],
         [ 0.0549,  0.1178],
         [ 0.0434,  0.0285],
         [ 0.0988,  0.0667],
         [ 0.0488, -0.0448],
         [-0.1157, -0.0312]],
        [[-0.0262,  0.0106],
         [-0.0159,  0.0584],
         [ 0.0959, -0.0585],
         [-0.1370, -0.0741],
         [-0.0691,  0.0818],
         [-0.0931, -0.0136],
         [-0.0306, -0.0876],
         [ 0.0654, -0.0601],
         [-0.0075, -0.1015],
         [-0.0146,  0.0205],
         [-0.0059, -0.0539],
         [ 0.0429, -0.0374],
         [-0.0800, -0.1064],
         [-0.0306, -0.1364],
         [ 0.1198, -0.0690],
         [-0.0598,  0.0133],
         [ 0.0374, -0.0136],
         [ 0.0990, -0.0841],
         [ 0.0517, -0.0003],
         [-0.1174, -0.0559],
         [ 0.0367,  0.0276],
         [ 0.1050,  0.0966],
         [-0.0787, -0.0616],
         [-0.0306, -0.1034]],
        [[-0.0390, -0.1181],
         [ 0.0549,  0.1021],
         [ 0.0114, -0.1033],
         [-0.1093, -0.0562],
         [ 0.0420,  0.0035],
         [ 0.0262,  0.1360],
         [ 0.0670,  0.0310],
         [-0.0292,  0.0683],
         [ 0.0528, -0.1299],
         [-0.0853,  0.0048],
         [ 0.0548,  0.0702],
         [-0.0859, -0.1432],
         [-0.0075, -0.0165],
         [ 0.0419, -0.0397],
         [ 0.1103,  0.0096],
         [ 0.1054, -0.1005],
         [ 0.0577,  0.0172],
         [-0.0722,  0.0716],
         [-0.1420,  0.1167],
         [ 0.0116,  0.0139],
         [ 0.0667,  0.0120],
         [ 0.0619,  0.0918],
         [-0.1126,  0.0955],
         [-0.0216, -0.0336]],
        [[ 0.0291,  0.1129],
         [-0.0785, -0.0973],
         [ 0.0896, -0.0678],
         [ 0.0465, -0.0213],
         [ 0.0397,  0.1101],
         [-0.0732, -0.0700],
         [ 0.0708,  0.0079],
         [-0.0159, -0.1268],
         [ 0.1223, -0.0055],
         [-0.0266, -0.0592],
         [-0.0285,  0.0702],
         [-0.0033,  0.1234],
         [-0.0083, -0.0207],
         [ 0.0815, -0.0037],
         [-0.0288,  0.0482],
         [ 0.1138,  0.0360],
         [ 0.1005,  0.0935],
         [ 0.0408,  0.0502],
         [ 0.0466,  0.0150],
         [ 0.1228,  0.1332],
         [ 0.0514, -0.0072],
         [ 0.1294, -0.1123],
         [ 0.1061,  0.0765],
         [ 0.0927, -0.0111]],
        [[-0.1077,  0.1030],
         [-0.0631,  0.0380],
         [ 0.0818, -0.1349],
         [ 0.0096, -0.0513],
         [ 0.1024, -0.0919],
         [ 0.0876,  0.0900],
         [ 0.0796,  0.1386],
         [ 0.0219, -0.1308],
         [ 0.1030,  0.0132],
         [ 0.0029, -0.1375],
         [-0.0324, -0.0701],
         [ 0.1414,  0.1028],
         [ 0.1077,  0.0988],
         [-0.0895, -0.0620],
         [-0.0565, -0.0579],
         [ 0.1124,  0.0490],
         [ 0.1157, -0.0068],
         [-0.1287, -0.0419],
         [ 0.1014,  0.0879],
         [ 0.0447, -0.0423],
         [-0.1347, -0.0776],
         [ 0.0753, -0.0582],
         [ 0.0690,  0.0394],
         [-0.0554,  0.0879]],
        [[-0.0464, -0.0048],
         [-0.0550, -0.1369],
         [ 0.0233,  0.0417],
         [-0.0727,  0.0885],
         [-0.1295, -0.1391],
         [-0.0891, -0.0499],
         [-0.0160, -0.0279],
         [ 0.0659, -0.1267],
         [ 0.0213,  0.0025],
         [ 0.0381,  0.1435],
         [ 0.0888, -0.0799],
         [-0.1183, -0.0349],
         [-0.0724,  0.0504],
         [ 0.0013,  0.1161],
         [ 0.0567, -0.0265],
         [ 0.0050,  0.0346],
         [-0.0179,  0.1165],
         [-0.1129,  0.0704],
         [-0.0920, -0.1265],
         [-0.0296,  0.0703],
         [ 0.1020,  0.0362],
         [-0.0125, -0.0081],
         [-0.0585, -0.0130],
         [-0.0100,  0.1228]],
        [[ 0.0845, -0.1155],
         [ 0.0006, -0.0888],
         [-0.0229, -0.1147],
         [ 0.0375, -0.1041],
         [ 0.1425,  0.1090],
         [-0.0994, -0.1359],
         [ 0.0056, -0.0403],
         [ 0.0424, -0.0977],
         [ 0.0591, -0.1247],
         [-0.0762, -0.0759],
         [ 0.0698, -0.0038],
         [-0.1387, -0.0824],
         [-0.0668, -0.1339],
         [ 0.0185,  0.0514],
         [-0.0265, -0.0574],
         [-0.0009, -0.1146],
         [-0.0879, -0.0033],
         [ 0.1282, -0.0444],
         [ 0.0715, -0.0568],
         [-0.0384, -0.1374],
         [ 0.1196,  0.1405],
         [-0.0030,  0.0917],
         [ 0.1181,  0.0717],
         [ 0.0743, -0.1374]]])
t_conv2.bias: tensor([-0.1356, -0.1108,  0.0451, -0.1248, -0.1102, -0.0700, -0.1330,  0.0002,
         0.0208, -0.0845,  0.0945, -0.0548, -0.0406,  0.1100,  0.1239, -0.0166,
        -0.1036, -0.0724,  0.0184,  0.0846,  0.0719, -0.0637, -0.1365, -0.1263])
Epoch: 1 	Training Loss: 0.670915
Model parameters after training:
conv1.weight: tensor([[[ 0.0901,  0.0978, -0.0276],
         [ 0.1083, -0.0258,  0.0238],
         [-0.0574,  0.0692,  0.1039],
         ...,
         [-0.0406,  0.0361, -0.0246],
         [ 0.0977, -0.0699, -0.0703],
         [-0.0703,  0.1060,  0.0393]],
        [[ 0.1134, -0.0973, -0.1169],
         [-0.0922, -0.0793,  0.0477],
         [ 0.0422,  0.0979, -0.0609],
         ...,
         [-0.0452, -0.0978, -0.1172],
         [ 0.0337, -0.0257,  0.0459],
         [-0.0967,  0.0875, -0.0865]],
        [[-0.0203,  0.0246,  0.0608],
         [ 0.0951,  0.1074, -0.0934],
         [ 0.0297, -0.0507, -0.0129],
         ...,
         [-0.1056, -0.0384,  0.0398],
         [ 0.0751,  0.0544, -0.1042],
         [-0.0709, -0.0186,  0.1140]],
        ...,
        [[-0.0612,  0.0476,  0.0200],
         [-0.0377, -0.0916, -0.0371],
         [-0.0497, -0.0384, -0.1063],
         ...,
         [-0.1109,  0.0541, -0.0535],
         [-0.0611,  0.0282, -0.0615],
         [-0.0545, -0.0397, -0.0443]],
        [[-0.0492, -0.0318,  0.0306],
         [-0.0954, -0.0713,  0.0017],
         [ 0.0164,  0.0651, -0.0828],
         ...,
         [ 0.0737,  0.0023,  0.0542],
         [-0.0422,  0.0513, -0.0379],
         [-0.0020, -0.1026, -0.0308]],
        [[-0.0620, -0.0398, -0.0753],
         [-0.1060,  0.0077,  0.0765],
         [ 0.1073,  0.0688, -0.0611],
         ...,
         [-0.0988,  0.0035, -0.0524],
         [-0.0579, -0.1079,  0.0625],
         [ 0.0227, -0.0996,  0.0935]]])
conv1.bias: tensor([ 0.0355,  0.0219, -0.0692,  0.0178,  0.1136,  0.0808, -0.0918,  0.1076,
         0.0091,  0.0567,  0.0915,  0.1005, -0.0919,  0.1032, -0.0800,  0.0088])
conv2.weight: tensor([[[-0.1009, -0.0316, -0.0066],
         [-0.0173, -0.0228,  0.0114],
         [ 0.1424,  0.0839,  0.0808],
         [ 0.0578,  0.1117, -0.0067],
         [ 0.0115,  0.0297, -0.1259],
         [-0.1163,  0.0177, -0.0565],
         [-0.0026, -0.0331,  0.0225],
         [ 0.0939, -0.0479,  0.1156],
         [ 0.1140, -0.1108, -0.1115],
         [-0.1168, -0.0791, -0.0562],
         [-0.0109, -0.0351, -0.0729],
         [-0.0459, -0.0522,  0.1416],
         [-0.0535, -0.1033,  0.0600],
         [-0.0083,  0.1105,  0.0902],
         [ 0.1326, -0.1057,  0.0928],
         [ 0.1211, -0.0713,  0.1327]],
        [[ 0.1082,  0.0016,  0.0696],
         [-0.0505, -0.1259,  0.0365],
         [ 0.0430, -0.0943,  0.0700],
         [-0.1233,  0.1242,  0.1398],
         [ 0.0393, -0.0906,  0.0702],
         [ 0.0246,  0.0392,  0.0474],
         [ 0.1099, -0.0620, -0.0325],
         [ 0.0394,  0.0157,  0.1164],
         [-0.0758, -0.0053,  0.0270],
         [-0.0383,  0.0984,  0.0158],
         [-0.1334, -0.0156, -0.0655],
         [ 0.0140, -0.0168, -0.1432],
         [-0.0263, -0.0138, -0.0426],
         [ 0.1326, -0.0315,  0.0927],
         [ 0.0358, -0.1218,  0.0339],
         [ 0.1196, -0.0944, -0.0933]],
        [[ 0.1413,  0.1160, -0.0805],
         [ 0.0869, -0.0185, -0.1423],
         [ 0.0108,  0.0466, -0.0433],
         [ 0.0502, -0.1234,  0.1000],
         [ 0.1231,  0.0796,  0.0245],
         [ 0.0475, -0.1044, -0.0361],
         [-0.0138, -0.0803, -0.1066],
         [ 0.0971,  0.0980, -0.1311],
         [ 0.0459,  0.0587,  0.1371],
         [ 0.0835,  0.1327, -0.0473],
         [ 0.1011,  0.1174, -0.1363],
         [-0.1159,  0.0292,  0.0788],
         [-0.0717,  0.0159, -0.0002],
         [ 0.0365, -0.0776,  0.0814],
         [ 0.0960, -0.1001,  0.0014],
         [ 0.0004,  0.0463,  0.1345]],
        [[ 0.0423, -0.0328,  0.1296],
         [-0.0549, -0.0419,  0.0099],
         [-0.1099,  0.0157, -0.0979],
         [ 0.0148,  0.0138,  0.0200],
         [-0.1217, -0.1371,  0.0664],
         [ 0.1238, -0.1281,  0.0535],
         [-0.1062,  0.0090,  0.1343],
         [ 0.1095, -0.1055,  0.0893],
         [ 0.0754, -0.0002,  0.1398],
         [-0.0573, -0.0336, -0.0730],
         [ 0.0208,  0.0382,  0.0115],
         [-0.0812, -0.0650,  0.0491],
         [-0.1266, -0.0225, -0.0032],
         [-0.0585,  0.0525,  0.0093],
         [ 0.1013, -0.0128, -0.0911],
         [ 0.1020,  0.0202, -0.0413]]])
conv2.bias: tensor([-0.0951,  0.0338, -0.1377,  0.0380])
t_conv1.weight: tensor([[[ 8.7406e-02, -1.5507e-01],
         [-1.1573e-01, -1.2709e-01],
         [ 1.4858e-01,  1.5028e-01],
         [ 1.1066e-02,  1.6596e-01],
         [-5.9097e-02, -1.7162e-01],
         [ 6.1747e-02,  6.2626e-02],
         [ 1.7331e-01, -5.1166e-05],
         [ 1.3548e-01,  1.0836e-01],
         [ 1.2795e-01, -1.7542e-01],
         [ 1.4557e-01, -1.5069e-01],
         [ 1.5848e-01, -7.3257e-03],
         [-1.5666e-01,  4.9160e-02],
         [-3.5982e-02, -1.5878e-01],
         [-6.4088e-02,  1.8227e-02],
         [ 1.3768e-01, -5.4346e-02],
         [ 1.0500e-01,  2.2137e-02]],
        [[ 5.9588e-03,  3.3825e-02],
         [-1.1601e-01, -1.4694e-01],
         [-5.5545e-02, -1.6473e-01],
         [-8.2440e-02,  8.1328e-03],
         [-1.1643e-01, -7.3326e-02],
         [-3.1764e-02, -2.0365e-02],
         [-9.7583e-02,  8.4943e-03],
         [-2.4812e-02,  5.0557e-02],
         [ 7.9846e-03, -8.8277e-02],
         [-6.0861e-02, -2.0375e-03],
         [-1.1031e-01,  1.3839e-02],
         [-1.2481e-02,  6.8586e-02],
         [ 4.1837e-02,  1.3230e-01],
         [-5.8275e-03, -1.3062e-01],
         [ 7.9021e-02, -1.1947e-01],
         [-2.4298e-02, -5.7241e-02]],
        [[-6.7077e-02, -6.5405e-02],
         [ 1.6244e-01,  1.0120e-01],
         [ 4.8991e-02,  1.6599e-01],
         [-1.6020e-01,  2.8526e-02],
         [ 1.1317e-01,  1.1743e-01],
         [-1.4069e-01,  6.2913e-02],
         [-1.0071e-01, -6.9073e-03],
         [-3.6888e-02, -1.4760e-01],
         [-1.6863e-01, -1.1630e-01],
         [ 8.0216e-02,  8.0864e-02],
         [-1.5375e-01, -6.6387e-02],
         [ 2.8875e-03, -1.5284e-01],
         [ 9.9606e-02,  1.6011e-01],
         [ 3.1265e-02, -1.3135e-01],
         [ 4.1222e-02,  6.4172e-02],
         [ 1.3998e-01, -9.4058e-02]],
        [[-1.5838e-01,  7.7667e-02],
         [ 1.1005e-02, -5.7599e-02],
         [-7.4073e-02, -9.1149e-02],
         [ 1.4310e-01, -3.0501e-02],
         [ 1.2749e-01,  1.5780e-01],
         [ 2.2393e-02,  3.7657e-02],
         [-1.2039e-02,  1.2141e-01],
         [-1.5929e-01,  7.0301e-02],
         [-2.8802e-02,  8.0719e-02],
         [-7.8737e-04, -6.5454e-02],
         [-1.9083e-02,  9.5458e-02],
         [-1.2278e-01, -1.1174e-01],
         [-3.9597e-02, -6.4121e-02],
         [ 6.9445e-02,  1.1897e-01],
         [-1.8933e-02,  1.6716e-01],
         [-7.3861e-02, -9.9200e-02]]])
t_conv1.bias: tensor([-0.0791, -0.1218, -0.1239, -0.1575, -0.1567,  0.0461,  0.1078,  0.1660,
         0.1506, -0.0102,  0.0343, -0.1058,  0.0683, -0.1695,  0.0834,  0.0324])
t_conv2.weight: tensor([[[ 0.0444,  0.0528],
         [-0.0663,  0.1239],
         [ 0.0689,  0.0948],
         [ 0.0191,  0.0906],
         [ 0.0971,  0.0654],
         [ 0.1100, -0.0262],
         [ 0.0949,  0.0333],
         [ 0.0868,  0.1406],
         [ 0.0327, -0.0536],
         [-0.0144,  0.0406],
         [ 0.0243, -0.0394],
         [ 0.1131,  0.0867],
         [-0.0897, -0.0118],
         [-0.0139, -0.0905],
         [ 0.0211, -0.0443],
         [-0.0745, -0.0464],
         [-0.0515,  0.1381],
         [ 0.0554,  0.1420],
         [ 0.0396,  0.0327],
         [ 0.0593,  0.0248],
         [-0.1133, -0.0854],
         [-0.0350,  0.0022],
         [ 0.0544,  0.0556],
         [ 0.1145,  0.0294]],
        [[-0.0493, -0.1085],
         [-0.1057, -0.0862],
         [ 0.0435,  0.0780],
         [ 0.1263, -0.0457],
         [-0.0114, -0.0429],
         [-0.0005,  0.0463],
         [-0.0032,  0.0067],
         [ 0.0183,  0.0538],
         [-0.0438, -0.0861],
         [ 0.0341, -0.0171],
         [-0.0654,  0.0606],
         [ 0.0013, -0.0210],
         [-0.0699, -0.0190],
         [-0.1227,  0.0328],
         [ 0.0022,  0.0876],
         [ 0.0093,  0.0115],
         [ 0.0393,  0.1098],
         [-0.0682,  0.0862],
         [ 0.0353, -0.0963],
         [ 0.0503, -0.0866],
         [-0.0454, -0.0688],
         [-0.0982,  0.1137],
         [-0.1290,  0.0722],
         [-0.1299, -0.0176]],
        [[ 0.0086,  0.1026],
         [-0.0522,  0.0415],
         [ 0.0224,  0.0849],
         [ 0.0086,  0.0540],
         [-0.0872, -0.1003],
         [ 0.1286, -0.1052],
         [-0.0246, -0.0174],
         [ 0.1411, -0.0312],
         [-0.1099, -0.0366],
         [ 0.0745,  0.0572],
         [ 0.1194, -0.0295],
         [ 0.0680, -0.1358],
         [ 0.0558,  0.0663],
         [ 0.0931, -0.0828],
         [-0.0385,  0.0349],
         [-0.1026, -0.1148],
         [-0.1389,  0.0081],
         [ 0.0896,  0.0371],
         [ 0.0088,  0.0503],
         [-0.0907,  0.0152],
         [-0.0359, -0.0715],
         [ 0.1245, -0.1117],
         [ 0.0212, -0.1268],
         [-0.0049, -0.0641]],
        [[ 0.0475, -0.0811],
         [ 0.0924, -0.1171],
         [ 0.0867, -0.1084],
         [ 0.0773, -0.0608],
         [-0.0003, -0.0263],
         [ 0.0937,  0.0473],
         [-0.1272,  0.0133],
         [-0.0996,  0.1079],
         [ 0.0237, -0.0371],
         [-0.0736,  0.0500],
         [-0.0864,  0.0685],
         [ 0.0788,  0.0886],
         [ 0.0377, -0.1263],
         [ 0.1038, -0.0448],
         [-0.0427, -0.0155],
         [ 0.1055,  0.1110],
         [ 0.0223,  0.0689],
         [-0.1345,  0.0003],
         [-0.1277,  0.0491],
         [-0.1028, -0.0514],
         [ 0.1009,  0.1379],
         [-0.0867, -0.0801],
         [ 0.0179,  0.0567],
         [-0.0235, -0.0451]],
        [[-0.0948,  0.0616],
         [ 0.1414, -0.0699],
         [ 0.0681,  0.0705],
         [ 0.1160, -0.0164],
         [ 0.0045,  0.1060],
         [ 0.0912,  0.1426],
         [-0.0414,  0.0571],
         [ 0.1008, -0.0980],
         [ 0.0287, -0.0323],
         [ 0.0928, -0.0648],
         [ 0.0101,  0.0864],
         [-0.1322, -0.1219],
         [-0.0739,  0.0926],
         [ 0.0968, -0.0986],
         [ 0.0275, -0.0765],
         [-0.0670,  0.1245],
         [ 0.0697, -0.0395],
         [ 0.0212,  0.0280],
         [ 0.0338, -0.0494],
         [-0.0850,  0.0956],
         [ 0.0194,  0.0604],
         [-0.0547,  0.0699],
         [ 0.1050,  0.0878],
         [ 0.0392,  0.1420]],
        [[-0.0003,  0.0307],
         [ 0.1371,  0.1403],
         [-0.0609,  0.1300],
         [ 0.0533, -0.0162],
         [ 0.1260, -0.0748],
         [ 0.0938,  0.1430],
         [-0.0995, -0.0852],
         [-0.1430, -0.0260],
         [-0.1311, -0.0483],
         [ 0.0438,  0.1020],
         [ 0.0804,  0.0801],
         [ 0.0599, -0.0895],
         [-0.1146,  0.0060],
         [ 0.1371,  0.0081],
         [-0.0124, -0.0980],
         [-0.0716, -0.1113],
         [ 0.1156, -0.0235],
         [-0.1275,  0.0155],
         [ 0.0105, -0.0178],
         [ 0.0517,  0.0776],
         [-0.1357, -0.1106],
         [-0.0069, -0.1338],
         [-0.1311,  0.1274],
         [-0.0110, -0.0714]],
        [[-0.0495, -0.1127],
         [ 0.1126, -0.0313],
         [-0.0812, -0.1095],
         [ 0.0844, -0.0200],
         [-0.0152, -0.0376],
         [-0.0697,  0.0257],
         [ 0.1110, -0.0837],
         [ 0.0069, -0.1098],
         [-0.0677,  0.1267],
         [ 0.0015,  0.1390],
         [-0.0253, -0.0787],
         [-0.0862,  0.1279],
         [-0.1110,  0.0757],
         [ 0.0359,  0.0426],
         [ 0.0814, -0.0378],
         [ 0.0893, -0.1150],
         [-0.0508,  0.1057],
         [ 0.0428, -0.0192],
         [-0.0337, -0.0881],
         [ 0.0878, -0.0046],
         [-0.0049,  0.0341],
         [ 0.1065, -0.0736],
         [-0.0497,  0.0978],
         [ 0.0815, -0.0710]],
        [[-0.1428,  0.0268],
         [ 0.0759,  0.0345],
         [ 0.1024, -0.1145],
         [ 0.0728, -0.0897],
         [ 0.0812,  0.1073],
         [ 0.0457,  0.1168],
         [-0.0951, -0.1291],
         [-0.1388,  0.0906],
         [ 0.0506, -0.1057],
         [ 0.0699,  0.1317],
         [-0.1423,  0.1047],
         [ 0.0221,  0.0134],
         [ 0.1299,  0.1307],
         [ 0.0608,  0.1140],
         [ 0.0600,  0.0235],
         [-0.1269,  0.0270],
         [-0.1027,  0.0444],
         [ 0.0255,  0.0032],
         [-0.0987, -0.0875],
         [ 0.1067,  0.0703],
         [ 0.0761, -0.0430],
         [-0.0249, -0.0370],
         [ 0.0993, -0.0623],
         [ 0.0909,  0.0995]],
        [[-0.1320,  0.0009],
         [-0.0275, -0.0798],
         [ 0.0623, -0.0175],
         [ 0.1264, -0.0903],
         [ 0.0671, -0.1232],
         [-0.0723,  0.0098],
         [ 0.1140,  0.0760],
         [-0.1185,  0.0160],
         [-0.0851,  0.0063],
         [-0.1202, -0.0423],
         [ 0.0990, -0.1324],
         [-0.1376,  0.0263],
         [ 0.0198, -0.0264],
         [ 0.1260, -0.0869],
         [-0.0876, -0.1079],
         [-0.0269, -0.0368],
         [ 0.0893, -0.0081],
         [ 0.0461, -0.0600],
         [ 0.1171,  0.1217],
         [-0.1293, -0.0371],
         [-0.1225,  0.0613],
         [-0.1261, -0.0682],
         [ 0.1442, -0.1378],
         [ 0.1065,  0.0122]],
        [[ 0.1154, -0.0732],
         [ 0.0948,  0.0174],
         [ 0.0111,  0.0985],
         [-0.1372, -0.1163],
         [ 0.1394, -0.0867],
         [-0.1040, -0.0071],
         [-0.0462, -0.0197],
         [-0.0967,  0.0521],
         [-0.1242,  0.0117],
         [ 0.0842,  0.0277],
         [ 0.0192,  0.0211],
         [-0.0423, -0.0275],
         [-0.0609, -0.0975],
         [-0.0764,  0.1427],
         [-0.0242,  0.0506],
         [ 0.0998, -0.0113],
         [-0.0776, -0.0978],
         [-0.0532,  0.0515],
         [-0.1216, -0.0176],
         [ 0.0549,  0.1178],
         [ 0.0434,  0.0285],
         [ 0.0988,  0.0667],
         [ 0.0488, -0.0448],
         [-0.1157, -0.0312]],
        [[-0.0262,  0.0106],
         [-0.0159,  0.0584],
         [ 0.0959, -0.0585],
         [-0.1370, -0.0741],
         [-0.0691,  0.0818],
         [-0.0931, -0.0136],
         [-0.0306, -0.0876],
         [ 0.0654, -0.0601],
         [-0.0075, -0.1015],
         [-0.0146,  0.0205],
         [-0.0059, -0.0539],
         [ 0.0429, -0.0374],
         [-0.0800, -0.1064],
         [-0.0306, -0.1364],
         [ 0.1198, -0.0690],
         [-0.0598,  0.0133],
         [ 0.0374, -0.0136],
         [ 0.0990, -0.0841],
         [ 0.0517, -0.0003],
         [-0.1174, -0.0559],
         [ 0.0367,  0.0276],
         [ 0.1050,  0.0966],
         [-0.0787, -0.0616],
         [-0.0306, -0.1034]],
        [[-0.0390, -0.1181],
         [ 0.0549,  0.1021],
         [ 0.0114, -0.1033],
         [-0.1093, -0.0562],
         [ 0.0420,  0.0035],
         [ 0.0262,  0.1360],
         [ 0.0670,  0.0310],
         [-0.0292,  0.0683],
         [ 0.0528, -0.1299],
         [-0.0853,  0.0048],
         [ 0.0548,  0.0702],
         [-0.0859, -0.1432],
         [-0.0075, -0.0165],
         [ 0.0419, -0.0397],
         [ 0.1103,  0.0096],
         [ 0.1054, -0.1005],
         [ 0.0577,  0.0172],
         [-0.0722,  0.0716],
         [-0.1420,  0.1167],
         [ 0.0116,  0.0139],
         [ 0.0667,  0.0120],
         [ 0.0619,  0.0918],
         [-0.1126,  0.0955],
         [-0.0216, -0.0336]],
        [[ 0.0291,  0.1129],
         [-0.0785, -0.0973],
         [ 0.0896, -0.0678],
         [ 0.0465, -0.0213],
         [ 0.0397,  0.1101],
         [-0.0732, -0.0700],
         [ 0.0708,  0.0079],
         [-0.0159, -0.1268],
         [ 0.1223, -0.0055],
         [-0.0266, -0.0592],
         [-0.0285,  0.0702],
         [-0.0033,  0.1234],
         [-0.0083, -0.0207],
         [ 0.0815, -0.0037],
         [-0.0288,  0.0482],
         [ 0.1138,  0.0360],
         [ 0.1005,  0.0935],
         [ 0.0408,  0.0502],
         [ 0.0466,  0.0150],
         [ 0.1228,  0.1332],
         [ 0.0514, -0.0072],
         [ 0.1294, -0.1123],
         [ 0.1061,  0.0765],
         [ 0.0927, -0.0111]],
        [[-0.1077,  0.1030],
         [-0.0631,  0.0380],
         [ 0.0818, -0.1349],
         [ 0.0096, -0.0513],
         [ 0.1024, -0.0919],
         [ 0.0876,  0.0900],
         [ 0.0796,  0.1386],
         [ 0.0219, -0.1308],
         [ 0.1030,  0.0132],
         [ 0.0029, -0.1375],
         [-0.0324, -0.0701],
         [ 0.1414,  0.1028],
         [ 0.1077,  0.0988],
         [-0.0895, -0.0620],
         [-0.0565, -0.0579],
         [ 0.1124,  0.0490],
         [ 0.1157, -0.0068],
         [-0.1287, -0.0419],
         [ 0.1014,  0.0879],
         [ 0.0447, -0.0423],
         [-0.1347, -0.0776],
         [ 0.0753, -0.0582],
         [ 0.0690,  0.0394],
         [-0.0554,  0.0879]],
        [[-0.0464, -0.0048],
         [-0.0550, -0.1369],
         [ 0.0233,  0.0417],
         [-0.0727,  0.0885],
         [-0.1295, -0.1391],
         [-0.0891, -0.0499],
         [-0.0160, -0.0279],
         [ 0.0659, -0.1267],
         [ 0.0213,  0.0025],
         [ 0.0381,  0.1435],
         [ 0.0888, -0.0799],
         [-0.1183, -0.0349],
         [-0.0724,  0.0504],
         [ 0.0013,  0.1161],
         [ 0.0567, -0.0265],
         [ 0.0050,  0.0346],
         [-0.0179,  0.1165],
         [-0.1129,  0.0704],
         [-0.0920, -0.1265],
         [-0.0296,  0.0703],
         [ 0.1020,  0.0362],
         [-0.0125, -0.0081],
         [-0.0585, -0.0130],
         [-0.0100,  0.1228]],
        [[ 0.0845, -0.1155],
         [ 0.0006, -0.0888],
         [-0.0229, -0.1147],
         [ 0.0375, -0.1041],
         [ 0.1425,  0.1090],
         [-0.0994, -0.1359],
         [ 0.0056, -0.0403],
         [ 0.0424, -0.0977],
         [ 0.0591, -0.1247],
         [-0.0762, -0.0759],
         [ 0.0698, -0.0038],
         [-0.1387, -0.0824],
         [-0.0668, -0.1339],
         [ 0.0185,  0.0514],
         [-0.0265, -0.0574],
         [-0.0009, -0.1146],
         [-0.0879, -0.0033],
         [ 0.1282, -0.0444],
         [ 0.0715, -0.0568],
         [-0.0384, -0.1374],
         [ 0.1196,  0.1405],
         [-0.0030,  0.0917],
         [ 0.1181,  0.0717],
         [ 0.0743, -0.1374]]])
t_conv2.bias: tensor([-0.1356, -0.1108,  0.0451, -0.1248, -0.1102, -0.0700, -0.1330,  0.0002,
         0.0208, -0.0845,  0.0945, -0.0548, -0.0406,  0.1100,  0.1239, -0.0166,
        -0.1036, -0.0724,  0.0184,  0.0846,  0.0719, -0.0637, -0.1365, -0.1263])
Traceback (most recent call last):
  File "/home/franlucc/projects/codetrace/train.py", line 292, in <module>
    train_loop(llm)
  File "/home/franlucc/projects/codetrace/train.py", line 210, in train_loop
    causal_loss, _ = apply_mask(llm, output, prompts, correct_idxs, incorrect_idxs)
  File "/home/franlucc/projects/codetrace/train.py", line 80, in apply_mask
    with llm.generate(max_new_tokens=1,
  File "/home/franlucc/venvs/gpu/lib/python3.10/site-packages/nnsight/contexts/Runner.py", line 73, in __exit__
    self.run_local()
  File "/home/franlucc/venvs/gpu/lib/python3.10/site-packages/nnsight/contexts/Runner.py", line 78, in run_local
    self.output = self.model(
  File "/home/franlucc/venvs/gpu/lib/python3.10/site-packages/nnsight/models/NNsightModel.py", line 194, in __call__
    output = fn(inputs, *args, **kwargs)
  File "/home/franlucc/venvs/gpu/lib/python3.10/site-packages/nnsight/models/LanguageModel.py", line 166, in _generation
    return super()._generation(
  File "/home/franlucc/venvs/gpu/lib/python3.10/site-packages/nnsight/models/NNsightModel.py", line 412, in _generation
    return self.local_model.generate(
  File "/home/franlucc/venvs/gpu/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/home/franlucc/venvs/gpu/lib/python3.10/site-packages/transformers/generation/utils.py", line 1474, in generate
    return self.greedy_search(
  File "/home/franlucc/venvs/gpu/lib/python3.10/site-packages/transformers/generation/utils.py", line 2335, in greedy_search
    outputs = self(
  File "/home/franlucc/venvs/gpu/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/franlucc/venvs/gpu/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1568, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/home/franlucc/venvs/gpu/lib/python3.10/site-packages/accelerate/hooks.py", line 165, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/home/franlucc/venvs/gpu/lib/python3.10/site-packages/transformers/models/gpt_bigcode/modeling_gpt_bigcode.py", line 1265, in forward
    transformer_outputs = self.transformer(
  File "/home/franlucc/venvs/gpu/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/franlucc/venvs/gpu/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/franlucc/venvs/gpu/lib/python3.10/site-packages/transformers/models/gpt_bigcode/modeling_gpt_bigcode.py", line 1118, in forward
    outputs = block(
  File "/home/franlucc/venvs/gpu/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/franlucc/venvs/gpu/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1581, in _call_impl
    hook_result = hook(self, args, result)
  File "/home/franlucc/venvs/gpu/lib/python3.10/site-packages/nnsight/intervention.py", line 321, in output_hook
    return self.output_hook(output, module_path)
  File "/home/franlucc/venvs/gpu/lib/python3.10/site-packages/nnsight/models/NNsightModel.py", line 184, in <lambda>
    output_hook=lambda activations, module_path: intervene(
  File "/home/franlucc/venvs/gpu/lib/python3.10/site-packages/nnsight/intervention.py", line 251, in intervene
    node.set_value(value)
  File "/home/franlucc/venvs/gpu/lib/python3.10/site-packages/nnsight/tracing/Node.py", line 279, in set_value
    listener.execute()
  File "/home/franlucc/venvs/gpu/lib/python3.10/site-packages/nnsight/tracing/Node.py", line 261, in execute
    self.set_value(output)
  File "/home/franlucc/venvs/gpu/lib/python3.10/site-packages/nnsight/tracing/Node.py", line 279, in set_value
    listener.execute()
  File "/home/franlucc/venvs/gpu/lib/python3.10/site-packages/nnsight/tracing/Node.py", line 261, in execute
    self.set_value(output)
  File "/home/franlucc/venvs/gpu/lib/python3.10/site-packages/nnsight/tracing/Node.py", line 279, in set_value
    listener.execute()
  File "/home/franlucc/venvs/gpu/lib/python3.10/site-packages/nnsight/tracing/Node.py", line 261, in execute
    self.set_value(output)
  File "/home/franlucc/venvs/gpu/lib/python3.10/site-packages/nnsight/tracing/Node.py", line 279, in set_value
    listener.execute()
  File "/home/franlucc/venvs/gpu/lib/python3.10/site-packages/nnsight/tracing/Node.py", line 261, in execute
    self.set_value(output)
  File "/home/franlucc/venvs/gpu/lib/python3.10/site-packages/nnsight/tracing/Node.py", line 279, in set_value
    listener.execute()
  File "/home/franlucc/venvs/gpu/lib/python3.10/site-packages/nnsight/tracing/Node.py", line 261, in execute
    self.set_value(output)
  File "/home/franlucc/venvs/gpu/lib/python3.10/site-packages/nnsight/tracing/Node.py", line 279, in set_value
    listener.execute()
  File "/home/franlucc/venvs/gpu/lib/python3.10/site-packages/nnsight/tracing/Node.py", line 230, in execute
    args, kwargs = self.prepare_inputs()
  File "/home/franlucc/venvs/gpu/lib/python3.10/site-packages/nnsight/tracing/Node.py", line 218, in prepare_inputs
    args = util.apply(args, _to, torch.Tensor)
  File "/home/franlucc/venvs/gpu/lib/python3.10/site-packages/nnsight/util.py", line 25, in apply
    return [apply(_data, fn, cls) for _data in data]
  File "/home/franlucc/venvs/gpu/lib/python3.10/site-packages/nnsight/util.py", line 25, in <listcomp>
    return [apply(_data, fn, cls) for _data in data]
  File "/home/franlucc/venvs/gpu/lib/python3.10/site-packages/nnsight/util.py", line 28, in apply
    return tuple([apply(_data, fn, cls) for _data in data])
  File "/home/franlucc/venvs/gpu/lib/python3.10/site-packages/nnsight/util.py", line 28, in <listcomp>
    return tuple([apply(_data, fn, cls) for _data in data])
  File "/home/franlucc/venvs/gpu/lib/python3.10/site-packages/nnsight/util.py", line 22, in apply
    return fn(data)
  File "/home/franlucc/venvs/gpu/lib/python3.10/site-packages/nnsight/tracing/Node.py", line 216, in _to
    return value.to(device)
KeyboardInterrupt