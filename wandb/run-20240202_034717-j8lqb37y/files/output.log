264
216
Training...
Traceback (most recent call last):
  File "/home/franlucc/projects/codetrace/train.py", line 266, in <module>
    train_loop(llm)
  File "/home/franlucc/projects/codetrace/train.py", line 191, in train_loop
    causal_loss, _ = apply_mask(llm, output, prompts, correct_idxs, incorrect_idxs)
  File "/home/franlucc/projects/codetrace/train.py", line 79, in apply_mask
    with llm.generate(max_new_tokens=1,
  File "/home/franlucc/venvs/gpu/lib/python3.10/site-packages/nnsight/contexts/Runner.py", line 73, in __exit__
    self.run_local()
  File "/home/franlucc/venvs/gpu/lib/python3.10/site-packages/nnsight/contexts/Runner.py", line 78, in run_local
    self.output = self.model(
  File "/home/franlucc/venvs/gpu/lib/python3.10/site-packages/nnsight/models/NNsightModel.py", line 194, in __call__
    output = fn(inputs, *args, **kwargs)
  File "/home/franlucc/venvs/gpu/lib/python3.10/site-packages/nnsight/models/LanguageModel.py", line 166, in _generation
    return super()._generation(
  File "/home/franlucc/venvs/gpu/lib/python3.10/site-packages/nnsight/models/NNsightModel.py", line 412, in _generation
    return self.local_model.generate(
  File "/home/franlucc/venvs/gpu/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/home/franlucc/venvs/gpu/lib/python3.10/site-packages/transformers/generation/utils.py", line 1474, in generate
    return self.greedy_search(
  File "/home/franlucc/venvs/gpu/lib/python3.10/site-packages/transformers/generation/utils.py", line 2335, in greedy_search
    outputs = self(
  File "/home/franlucc/venvs/gpu/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/franlucc/venvs/gpu/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1568, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/home/franlucc/venvs/gpu/lib/python3.10/site-packages/accelerate/hooks.py", line 166, in new_forward
    return module._hf_hook.post_forward(module, output)
  File "/home/franlucc/venvs/gpu/lib/python3.10/site-packages/accelerate/hooks.py", line 315, in post_forward
    output = send_to_device(output, self.input_device, skip_keys=self.skip_keys)
  File "/home/franlucc/venvs/gpu/lib/python3.10/site-packages/accelerate/utils/operations.py", line 161, in send_to_device
    {
  File "/home/franlucc/venvs/gpu/lib/python3.10/site-packages/accelerate/utils/operations.py", line 162, in <dictcomp>
    k: t if k in skip_keys else send_to_device(t, device, non_blocking=non_blocking, skip_keys=skip_keys)
  File "/home/franlucc/venvs/gpu/lib/python3.10/site-packages/accelerate/utils/operations.py", line 152, in send_to_device
    return honor_type(
  File "/home/franlucc/venvs/gpu/lib/python3.10/site-packages/accelerate/utils/operations.py", line 84, in honor_type
    return type(obj)(generator)
  File "/home/franlucc/venvs/gpu/lib/python3.10/site-packages/accelerate/utils/operations.py", line 153, in <genexpr>
    tensor, (send_to_device(t, device, non_blocking=non_blocking, skip_keys=skip_keys) for t in tensor)
  File "/home/franlucc/venvs/gpu/lib/python3.10/site-packages/accelerate/utils/operations.py", line 171, in send_to_device
    return tensor.to(device, non_blocking=non_blocking)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 4.04 GiB. GPU 0 has a total capacty of 79.14 GiB of which 582.75 MiB is free. Including non-PyTorch memory, this process has 78.57 GiB memory in use. Of the allocated memory 75.31 GiB is allocated by PyTorch, and 1.59 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF