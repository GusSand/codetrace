264
216
Training...
Batch loss: 0.13092711567878723
Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.
Traceback (most recent call last):
  File "/home/franlucc/projects/codetrace/train.py", line 265, in <module>
    train_loop(llm)
  File "/home/franlucc/projects/codetrace/train.py", line 197, in train_loop
    wandb.log({'training_loss': loss.item()}, epoch=epoch, batch_size=batch_size)
  File "/home/franlucc/venvs/gpu/lib/python3.10/site-packages/wandb/sdk/wandb_run.py", line 420, in wrapper
    return func(self, *args, **kwargs)
  File "/home/franlucc/venvs/gpu/lib/python3.10/site-packages/wandb/sdk/wandb_run.py", line 371, in wrapper_fn
    return func(self, *args, **kwargs)
  File "/home/franlucc/venvs/gpu/lib/python3.10/site-packages/wandb/sdk/wandb_run.py", line 361, in wrapper
    return func(self, *args, **kwargs)
TypeError: Run.log() got an unexpected keyword argument 'epoch'