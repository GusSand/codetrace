{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = datasets.load_dataset(\"franlucc/py_all_mutations_v3_starcoderbase-1b\", split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['mutated_program', 'mutations', 'key', 'prefix', 'suffix', 'middle', 'correct', 'model', 'fim_type', 'fim_program', 'hexsha', 'mutated_generated_text'],\n",
       "    num_rows: 7320\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import logging\n",
      "import shutil\n",
      "import os\n",
      "\n",
      "from zerver.data_import.import_util import (\n",
      "    build_attachment,\n",
      "    create_converted_data_files,\n",
      ")\n",
      "\n",
      "from typing import Any, Dict, List, Optional\n",
      "\n",
      "class AttachmentHandler:\n",
      "    def __init__(__tmp3) -> None:\n",
      "        __tmp3.info_dict = dict()  # type: Dict[str, Dict[str, Any]]\n",
      "\n",
      "    def __tmp6(__tmp3,\n",
      "                            realm_id: int,\n",
      "                            __tmp0: <FILL>,\n",
      "                            sender_id: int,\n",
      "                            attachment: Dict[str, Any],\n",
      "                            files_dir) -> Optional[str]:\n",
      "        if not attachment:\n",
      "            return None\n",
      "\n",
      "        name = attachment['name']\n",
      "\n",
      "        if 'path' not in attachment:\n",
      "            logging.info('Skipping HipChat attachment with missing path data: ' + name)\n",
      "            return None\n",
      "\n",
      "        size = attachment['size']\n",
      "        path = attachment['path']\n",
      "\n",
      "        local_fn = os.path.join(files_dir, path)\n",
      "\n",
      "        target_path = os.path.join(\n",
      "            str(realm_id),\n",
      "            'HipChatImportAttachment',\n",
      "            path\n",
      "        )\n",
      "\n",
      "        if target_path in __tmp3.info_dict:\n",
      "            logging.info(\"file used multiple times: \" + path)\n",
      "            info = __tmp3.info_dict[target_path]\n",
      "            info['message_ids'].add(__tmp0)\n",
      "            return info['content']\n",
      "\n",
      "        # HipChat provides size info, but it's not\n",
      "        # completely trustworthy, so we we just\n",
      "        # ask the OS for file details.\n",
      "        size = os.path.getsize(local_fn)\n",
      "        mtime = os.path.getmtime(local_fn)\n",
      "\n",
      "        content = '[{name}](/user_uploads/{path})'.format(\n",
      "            name=name,\n",
      "            path=target_path,\n",
      "        )\n",
      "\n",
      "        info = dict(\n",
      "            message_ids={__tmp0},\n",
      "            sender_id=sender_id,\n",
      "            local_fn=local_fn,\n",
      "            target_path=target_path,\n",
      "            name=name,\n",
      "            size=size,\n",
      "            mtime=mtime,\n",
      "            content=content,\n",
      "        )\n",
      "        __tmp3.info_dict[target_path] = info\n",
      "\n",
      "        return content\n",
      "\n",
      "    def __tmp4(__tmp3, __tmp7: str, realm_id: int) -> None:\n",
      "        attachments = []  # type: List[Dict[str, Any]]\n",
      "        uploads_records = []  # type: List[Dict[str, Any]]\n",
      "\n",
      "        def add_attachment(info) -> None:\n",
      "            build_attachment(\n",
      "                realm_id=realm_id,\n",
      "                message_ids=info['message_ids'],\n",
      "                user_id=info['sender_id'],\n",
      "                fileinfo=dict(\n",
      "                    created=info['mtime'],  # minor lie\n",
      "                    size=info['size'],\n",
      "                    name=info['name'],\n",
      "                ),\n",
      "                s3_path=info['target_path'],\n",
      "                zerver_attachment=attachments,\n",
      "            )\n",
      "\n",
      "        def __tmp2(info) -> None:\n",
      "            target_path = info['target_path']\n",
      "            upload_rec = dict(\n",
      "                size=info['size'],\n",
      "                user_profile_id=info['sender_id'],\n",
      "                realm_id=realm_id,\n",
      "                s3_path=target_path,\n",
      "                path=target_path,\n",
      "                content_type=None,\n",
      "            )\n",
      "            uploads_records.append(upload_rec)\n",
      "\n",
      "        def __tmp5(info) :\n",
      "            target_path = info['target_path']\n",
      "            full_target_path = os.path.join(\n",
      "                __tmp7,\n",
      "                'uploads',\n",
      "                target_path,\n",
      "            )\n",
      "            full_target_path = os.path.abspath(full_target_path)\n",
      "            os.makedirs(os.path.dirname(full_target_path), exist_ok=True)\n",
      "            return full_target_path\n",
      "\n",
      "        def __tmp1(info) -> None:\n",
      "            source_path = info['local_fn']\n",
      "            target_path = __tmp5(info)\n",
      "            shutil.copyfile(source_path, target_path)\n",
      "\n",
      "        logging.info('Start processing attachment files')\n",
      "\n",
      "        for info in __tmp3.info_dict.values():\n",
      "            add_attachment(info)\n",
      "            __tmp2(info)\n",
      "            __tmp1(info)\n",
      "\n",
      "        uploads_folder = os.path.join(__tmp7, 'uploads')\n",
      "        os.makedirs(os.path.join(uploads_folder, str(realm_id)), exist_ok=True)\n",
      "\n",
      "        attachment = dict(\n",
      "            zerver_attachment=attachments\n",
      "        )\n",
      "\n",
      "        create_converted_data_files(uploads_records, __tmp7, '/uploads/records.json')\n",
      "        create_converted_data_files(attachment, __tmp7, '/attachment.json')\n",
      "\n",
      "        logging.info('Done processing attachment files')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(ds[8][\"mutated_program\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = datasets.load_from_disk(\"/home/franlucc/projects_data/codetrace/results_v2/starcoderbase-1b/python/all_muts/ood_steering_results_ds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['steered_generation', 'correct_steer', 'fim_program', 'fim_type', 'hexsha'],\n",
       "    num_rows: 631\n",
       "})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#!/usr/bin/env python3\n",
      "# Copyright (C) 2021 Checkmk GmbH - License: GNU General Public License v2\n",
      "# This file is part of Checkmk (https://checkmk.com). It is subject to the terms and\n",
      "# conditions defined in the file COPYING, which is part of this source code package.\n",
      "\n",
      "from collections.abc import Sequence\n",
      "\n",
      "import pytest\n",
      "from polyfactory.factories.pydantic_factory import ModelFactory\n",
      "from pytest_mock import MockerFixture\n",
      "\n",
      "from cmk.base.plugins.agent_based.agent_based_api.v1 import Attributes, TableRow\n",
      "from cmk.base.plugins.agent_based.inventory_kube_node import inventory_kube_node\n",
      "\n",
      "from cmk.plugins.lib.kube import (\n",
      "    HealthZ,\n",
      "    IpAddress,\n",
      "    KubeletInfo,\n",
      "    NodeAddress,\n",
      "    NodeInfo,\n",
      "    NodeName,\n",
      "    Timestamp,\n",
      ")\n",
      "\n",
      "from .utils_inventory import sort_inventory_result\n",
      "\n",
      "\n",
      "@pytest.mark.parametrize(\n",
      "    \"section_info, section_kubelet, expected_check_result\",\n",
      "    [\n",
      "        pytest.param(\n",
      "            NodeInfo(\n",
      "                architecture=\"amd64\",\n",
      "                kernel_version=\"5.13.0-27-generic\",\n",
      "                os_image=\"Ubuntu 20.04.2 LTS\",\n",
      "                operating_system=\"linux\",\n",
      "                container_runtime_version=IpAddress(\"docker://20.10.8\"),\n",
      "                name=NodeName(\"minikube\"),\n",
      "                creation_timestamp=Timestamp(1640000000.0),\n",
      "                labels={},\n",
      "                annotations={},\n",
      "                addresses=[\n",
      "                    NodeAddress(type_=\"Hostname\", address=IpAddress(\"k8-21\")),\n",
      "                    NodeAddress(type_=\"ExternalIP\", address=IpAddress(\"10.200.3.21\")),\n",
      "                ],\n",
      "                cluster=\"cluster\",\n",
      "                kubernetes_cluster_hostname=\"host\",\n",
      "            ),\n",
      "            KubeletInfo(\n",
      "                version=\"1.2.3\",\n",
      "                proxy_version=\"1.2.3\",\n",
      "                health=HealthZ(status_code=200, response=\"ok\"),\n",
      "            ),\n",
      "            [\n",
      "                Attributes(\n",
      "                    path=[\"software\", \"applications\", \"kube\", \"metadata\"],\n",
      "                    inventory_attributes={\n",
      "                        \"object\": \"Node\",\n",
      "                        \"name\": \"minikube\",\n",
      "                    },\n",
      "                ),\n",
      "                Attributes(\n",
      "                    path=[\"software\", \"applications\", \"kube\", \"node\"],\n",
      "                    inventory_attributes={\n",
      "                        \"operating_system\": \"linux\",\n",
      "                        \"os_image\": \"Ubuntu 20.04.2 LTS\",\n",
      "                        \"kernel_version\": \"5.13.0-27-generic\",\n",
      "                        \"architecture\": \"amd64\",\n",
      "                        \"container_runtime_version\": \"docker://20.10.8\",\n",
      "                        \"kubelet_version\": \"1.2.3\",\n",
      "                        \"kube_proxy_version\": \"1.2.3\",\n",
      "                    },\n",
      "                    status_attributes={},\n",
      "                ),\n",
      "                TableRow(\n",
      "                    path=[\"networking\", \"kube\"],\n",
      "                    key_columns={\"ip\": \"k8-21\"},\n",
      "                    inventory_columns={\"address_type\": \"Hostname\"},\n",
      "                    status_columns={},\n",
      "                ),\n",
      "                TableRow(\n",
      "                    path=[\"networking\", \"kube\"],\n",
      "                    key_columns={\"ip\": \"10.200.3.21\"},\n",
      "                    inventory_columns={\"address_type\": \"ExternalIP\"},\n",
      "                    status_columns={},\n",
      "                ),\n",
      "            ],\n",
      "            id=\"overall look of node inventory\",\n",
      "        ),\n",
      "    ],\n",
      ")\n",
      "def test_inventory_kube_node(\n",
      "    __tmp1: <FILL>,\n",
      "    __tmp2,\n",
      "    expected_check_result: Sequence[TableRow | Attributes],\n",
      ") -> None:\n",
      "    assert sort_inventory_result(\n",
      "        inventory_kube_node(__tmp1, __tmp2)\n",
      "    ) == sort_inventory_result(expected_check_result)\n",
      "\n",
      "\n",
      "def __tmp0(mocker: MockerFixture) -> None:\n",
      "    \"\"\"Test coverage and uniform look across inventories relies on the inventories calling\n",
      "    labels_to_table.\"\"\"\n",
      "\n",
      "    class __typ0(ModelFactory):\n",
      "        __model__ = NodeInfo\n",
      "\n",
      "    __tmp1 = __typ0.build()\n",
      "\n",
      "    class __typ1(ModelFactory):\n",
      "        __model__ = KubeletInfo\n",
      "\n",
      "    __tmp2 = __typ1.build()\n",
      "\n",
      "    mock = mocker.patch(\"cmk.base.plugins.agent_based.inventory_kube_node.labels_to_table\")\n",
      "    list(inventory_kube_node(__tmp1, __tmp2))\n",
      "    mock.assert_called_once()\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(ds[2][\"fim_program\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GPU_Codetrace",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
