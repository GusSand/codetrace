2025-07-24 22:40:40,724 - __main__ - INFO - üöÄ Starting CWE-Specific Neural Steering Experiment (NNSight 0.4.x)
2025-07-24 22:40:40,725 - __main__ - INFO - üß™ Experiment ID: 20250724_224040
2025-07-24 22:40:40,725 - __main__ - INFO - üöÄ Loading model: Qwen/Qwen2.5-14B-Instruct
2025-07-24 22:40:41,487 - __main__ - INFO - ‚úÖ Model loaded successfully
2025-07-24 22:40:41,487 - __main__ - INFO - üìä Model layers: 48
2025-07-24 22:40:41,487 - __main__ - INFO - üìö Loading REAL SecLLMHolmes dataset...
2025-07-24 22:40:41,487 - __main__ - INFO - üîç Found 8 CWE directories
2025-07-24 22:40:41,488 - __main__ - INFO - üìñ Loaded 6 examples for CWE-190
2025-07-24 22:40:41,488 - __main__ - INFO - üìñ Loaded 6 examples for CWE-22
2025-07-24 22:40:41,488 - __main__ - INFO - üìñ Loaded 6 examples for CWE-416
2025-07-24 22:40:41,489 - __main__ - INFO - üìñ Loaded 6 examples for CWE-476
2025-07-24 22:40:41,489 - __main__ - INFO - üìñ Loaded 6 examples for CWE-77
2025-07-24 22:40:41,489 - __main__ - INFO - üìñ Loaded 6 examples for CWE-787
2025-07-24 22:40:41,489 - __main__ - INFO - üìñ Loaded 6 examples for CWE-79
2025-07-24 22:40:41,490 - __main__ - INFO - üìñ Loaded 6 examples for CWE-89
2025-07-24 22:40:41,490 - __main__ - INFO - üìä Loaded 48 total REAL examples across 8 CWEs
2025-07-24 22:40:41,490 - __main__ - INFO -   CWE-190: 6 examples (3 vulnerable, 3 secure)
2025-07-24 22:40:41,490 - __main__ - INFO -   CWE-22: 6 examples (3 vulnerable, 3 secure)
2025-07-24 22:40:41,490 - __main__ - INFO -   CWE-416: 6 examples (3 vulnerable, 3 secure)
2025-07-24 22:40:41,490 - __main__ - INFO -   CWE-476: 6 examples (3 vulnerable, 3 secure)
2025-07-24 22:40:41,490 - __main__ - INFO -   CWE-77: 6 examples (3 vulnerable, 3 secure)
2025-07-24 22:40:41,490 - __main__ - INFO -   CWE-787: 6 examples (3 vulnerable, 3 secure)
2025-07-24 22:40:41,490 - __main__ - INFO -   CWE-79: 6 examples (3 vulnerable, 3 secure)
2025-07-24 22:40:41,491 - __main__ - INFO -   CWE-89: 6 examples (3 vulnerable, 3 secure)
2025-07-24 22:40:41,491 - __main__ - INFO - üéØ Processing CWE: CWE-190
2025-07-24 22:40:41,491 - __main__ - INFO - üéØ Creating steering vectors for CWE-190
2025-07-24 22:40:41,491 - __main__ - INFO - üìä Creating steering vectors from 3 vulnerable and 3 secure examples
2025-07-24 22:42:05,090 - accelerate.utils.modeling - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2025-07-24 22:42:25,326 - __main__ - ERROR - ‚ùå Error processing secure example: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.33 GiB of which 10.88 MiB is free. Including non-PyTorch memory, this process has 79.15 GiB memory in use. Of the allocated memory 76.73 GiB is allocated by PyTorch, and 1.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-24 22:42:25,341 - __main__ - ERROR - ‚ùå Error processing CWE-190: stack expects each tensor to be equal size, but got [156, 5120] at entry 0 and [199, 5120] at entry 1
2025-07-24 22:42:25,341 - __main__ - INFO - üéØ Processing CWE: CWE-22
2025-07-24 22:42:25,341 - __main__ - INFO - üéØ Creating steering vectors for CWE-22
2025-07-24 22:42:25,341 - __main__ - INFO - üìä Creating steering vectors from 3 vulnerable and 3 secure examples
2025-07-24 22:42:25,367 - __main__ - ERROR - ‚ùå Error processing vulnerable example: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.33 GiB of which 10.88 MiB is free. Including non-PyTorch memory, this process has 79.15 GiB memory in use. Of the allocated memory 76.73 GiB is allocated by PyTorch, and 1.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-24 22:42:25,374 - __main__ - ERROR - ‚ùå Error processing vulnerable example: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.33 GiB of which 10.88 MiB is free. Including non-PyTorch memory, this process has 79.15 GiB memory in use. Of the allocated memory 76.73 GiB is allocated by PyTorch, and 1.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-24 22:42:25,381 - __main__ - ERROR - ‚ùå Error processing vulnerable example: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.33 GiB of which 10.88 MiB is free. Including non-PyTorch memory, this process has 79.15 GiB memory in use. Of the allocated memory 76.73 GiB is allocated by PyTorch, and 1.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-24 22:42:25,388 - __main__ - ERROR - ‚ùå Error processing secure example: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.33 GiB of which 10.88 MiB is free. Including non-PyTorch memory, this process has 79.15 GiB memory in use. Of the allocated memory 76.73 GiB is allocated by PyTorch, and 1.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-24 22:42:25,394 - __main__ - ERROR - ‚ùå Error processing secure example: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.33 GiB of which 10.88 MiB is free. Including non-PyTorch memory, this process has 79.15 GiB memory in use. Of the allocated memory 76.73 GiB is allocated by PyTorch, and 1.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-24 22:42:26,111 - __main__ - WARNING - ‚ö†Ô∏è Could not create steering vector for layer -3
2025-07-24 22:42:28,141 - __main__ - ERROR - ‚ùå Error processing secure example: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.33 GiB of which 10.88 MiB is free. Including non-PyTorch memory, this process has 79.15 GiB memory in use. Of the allocated memory 77.31 GiB is allocated by PyTorch, and 1.35 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-24 22:42:28,327 - __main__ - ERROR - ‚ùå Error processing secure example: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.33 GiB of which 10.88 MiB is free. Including non-PyTorch memory, this process has 79.15 GiB memory in use. Of the allocated memory 76.64 GiB is allocated by PyTorch, and 2.02 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-24 22:42:28,643 - __main__ - ERROR - ‚ùå Error processing secure example: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.33 GiB of which 10.88 MiB is free. Including non-PyTorch memory, this process has 79.15 GiB memory in use. Of the allocated memory 76.64 GiB is allocated by PyTorch, and 2.02 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-24 22:42:28,643 - __main__ - WARNING - ‚ö†Ô∏è Could not create steering vector for layer -2
2025-07-24 22:42:28,651 - __main__ - ERROR - ‚ùå Error processing vulnerable example: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.33 GiB of which 10.88 MiB is free. Including non-PyTorch memory, this process has 79.15 GiB memory in use. Of the allocated memory 76.69 GiB is allocated by PyTorch, and 1.97 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-24 22:42:28,659 - __main__ - ERROR - ‚ùå Error processing vulnerable example: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.33 GiB of which 10.88 MiB is free. Including non-PyTorch memory, this process has 79.15 GiB memory in use. Of the allocated memory 76.70 GiB is allocated by PyTorch, and 1.96 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-24 22:42:28,665 - __main__ - ERROR - ‚ùå Error processing vulnerable example: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.33 GiB of which 10.88 MiB is free. Including non-PyTorch memory, this process has 79.15 GiB memory in use. Of the allocated memory 76.70 GiB is allocated by PyTorch, and 1.96 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-24 22:42:28,845 - __main__ - ERROR - ‚ùå Error processing secure example: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.33 GiB of which 10.88 MiB is free. Including non-PyTorch memory, this process has 79.15 GiB memory in use. Of the allocated memory 76.72 GiB is allocated by PyTorch, and 1.94 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-24 22:42:29,164 - __main__ - ERROR - ‚ùå Error processing secure example: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.33 GiB of which 10.88 MiB is free. Including non-PyTorch memory, this process has 79.15 GiB memory in use. Of the allocated memory 76.72 GiB is allocated by PyTorch, and 1.94 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-24 22:42:29,172 - __main__ - ERROR - ‚ùå Error processing secure example: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.33 GiB of which 10.88 MiB is free. Including non-PyTorch memory, this process has 79.15 GiB memory in use. Of the allocated memory 76.72 GiB is allocated by PyTorch, and 1.94 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-24 22:42:29,172 - __main__ - WARNING - ‚ö†Ô∏è Could not create steering vector for layer -1
2025-07-24 22:42:29,172 - __main__ - WARNING - ‚ö†Ô∏è No steering vectors created for CWE-22
2025-07-24 22:42:29,172 - __main__ - INFO - üéØ Processing CWE: CWE-416
2025-07-24 22:42:29,172 - __main__ - INFO - üéØ Creating steering vectors for CWE-416
2025-07-24 22:42:29,172 - __main__ - INFO - üìä Creating steering vectors from 3 vulnerable and 3 secure examples
2025-07-24 22:42:29,181 - __main__ - ERROR - ‚ùå Error processing vulnerable example: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.33 GiB of which 10.88 MiB is free. Including non-PyTorch memory, this process has 79.15 GiB memory in use. Of the allocated memory 76.75 GiB is allocated by PyTorch, and 1.91 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-24 22:42:29,188 - __main__ - ERROR - ‚ùå Error processing vulnerable example: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.33 GiB of which 10.88 MiB is free. Including non-PyTorch memory, this process has 79.15 GiB memory in use. Of the allocated memory 76.79 GiB is allocated by PyTorch, and 1.87 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-24 22:42:31,438 - __main__ - ERROR - ‚ùå Error processing secure example: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.33 GiB of which 8.88 MiB is free. Including non-PyTorch memory, this process has 79.15 GiB memory in use. Of the allocated memory 78.02 GiB is allocated by PyTorch, and 655.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-24 22:42:31,439 - __main__ - ERROR - ‚ùå Error processing CWE-416: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.33 GiB of which 8.88 MiB is free. Including non-PyTorch memory, this process has 79.15 GiB memory in use. Of the allocated memory 78.02 GiB is allocated by PyTorch, and 655.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-24 22:42:31,439 - __main__ - INFO - üéØ Processing CWE: CWE-476
2025-07-24 22:42:31,439 - __main__ - INFO - üéØ Creating steering vectors for CWE-476
2025-07-24 22:42:31,439 - __main__ - INFO - üìä Creating steering vectors from 3 vulnerable and 3 secure examples
2025-07-24 22:42:33,698 - __main__ - ERROR - ‚ùå Error processing secure example: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.33 GiB of which 6.88 MiB is free. Including non-PyTorch memory, this process has 79.15 GiB memory in use. Of the allocated memory 76.79 GiB is allocated by PyTorch, and 1.87 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-24 22:42:33,709 - __main__ - ERROR - ‚ùå Error processing secure example: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.33 GiB of which 6.88 MiB is free. Including non-PyTorch memory, this process has 79.15 GiB memory in use. Of the allocated memory 76.84 GiB is allocated by PyTorch, and 1.83 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-24 22:42:33,709 - __main__ - ERROR - ‚ùå Error processing CWE-476: stack expects each tensor to be equal size, but got [215, 5120] at entry 0 and [241, 5120] at entry 1
2025-07-24 22:42:33,709 - __main__ - INFO - üéØ Processing CWE: CWE-77
2025-07-24 22:42:33,709 - __main__ - INFO - üéØ Creating steering vectors for CWE-77
2025-07-24 22:42:33,709 - __main__ - INFO - üìä Creating steering vectors from 3 vulnerable and 3 secure examples
2025-07-24 22:42:33,718 - __main__ - ERROR - ‚ùå Error processing vulnerable example: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.33 GiB of which 6.88 MiB is free. Including non-PyTorch memory, this process has 79.15 GiB memory in use. Of the allocated memory 76.87 GiB is allocated by PyTorch, and 1.80 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-24 22:42:33,725 - __main__ - ERROR - ‚ùå Error processing vulnerable example: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.33 GiB of which 6.88 MiB is free. Including non-PyTorch memory, this process has 79.15 GiB memory in use. Of the allocated memory 76.90 GiB is allocated by PyTorch, and 1.77 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-24 22:42:35,783 - __main__ - ERROR - ‚ùå Error processing secure example: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.33 GiB of which 10.88 MiB is free. Including non-PyTorch memory, this process has 79.15 GiB memory in use. Of the allocated memory 75.94 GiB is allocated by PyTorch, and 2.72 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-24 22:42:35,784 - __main__ - ERROR - ‚ùå Error processing CWE-77: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.33 GiB of which 10.88 MiB is free. Including non-PyTorch memory, this process has 79.15 GiB memory in use. Of the allocated memory 75.94 GiB is allocated by PyTorch, and 2.72 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-24 22:42:35,784 - __main__ - INFO - üéØ Processing CWE: CWE-787
2025-07-24 22:42:35,784 - __main__ - INFO - üéØ Creating steering vectors for CWE-787
2025-07-24 22:42:35,785 - __main__ - INFO - üìä Creating steering vectors from 3 vulnerable and 3 secure examples
2025-07-24 22:42:35,793 - __main__ - ERROR - ‚ùå Error processing vulnerable example: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.33 GiB of which 10.88 MiB is free. Including non-PyTorch memory, this process has 79.15 GiB memory in use. Of the allocated memory 75.97 GiB is allocated by PyTorch, and 2.70 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-24 22:42:35,800 - __main__ - ERROR - ‚ùå Error processing vulnerable example: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.33 GiB of which 10.88 MiB is free. Including non-PyTorch memory, this process has 79.15 GiB memory in use. Of the allocated memory 75.97 GiB is allocated by PyTorch, and 2.70 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-24 22:42:35,807 - __main__ - ERROR - ‚ùå Error processing vulnerable example: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.33 GiB of which 8.88 MiB is free. Including non-PyTorch memory, this process has 79.15 GiB memory in use. Of the allocated memory 76.02 GiB is allocated by PyTorch, and 2.65 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-24 22:42:36,833 - __main__ - WARNING - ‚ö†Ô∏è Could not create steering vector for layer -3
2025-07-24 22:42:39,119 - __main__ - ERROR - ‚ùå Error processing secure example: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.33 GiB of which 4.88 MiB is free. Including non-PyTorch memory, this process has 79.16 GiB memory in use. Of the allocated memory 76.74 GiB is allocated by PyTorch, and 1.92 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-24 22:42:39,128 - __main__ - ERROR - ‚ùå Error processing secure example: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.33 GiB of which 4.88 MiB is free. Including non-PyTorch memory, this process has 79.16 GiB memory in use. Of the allocated memory 76.79 GiB is allocated by PyTorch, and 1.87 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-24 22:42:39,128 - __main__ - ERROR - ‚ùå Error processing CWE-787: stack expects each tensor to be equal size, but got [113, 5120] at entry 0 and [360, 5120] at entry 1
2025-07-24 22:42:39,128 - __main__ - INFO - üéØ Processing CWE: CWE-79
2025-07-24 22:42:39,128 - __main__ - INFO - üéØ Creating steering vectors for CWE-79
2025-07-24 22:42:39,128 - __main__ - INFO - üìä Creating steering vectors from 3 vulnerable and 3 secure examples
2025-07-24 22:42:39,135 - __main__ - ERROR - ‚ùå Error processing vulnerable example: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.33 GiB of which 4.88 MiB is free. Including non-PyTorch memory, this process has 79.16 GiB memory in use. Of the allocated memory 76.83 GiB is allocated by PyTorch, and 1.84 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-24 22:42:39,143 - __main__ - ERROR - ‚ùå Error processing vulnerable example: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.33 GiB of which 4.88 MiB is free. Including non-PyTorch memory, this process has 79.16 GiB memory in use. Of the allocated memory 76.86 GiB is allocated by PyTorch, and 1.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-24 22:42:40,407 - __main__ - ERROR - ‚ùå Error processing CWE-79: stack expects each tensor to be equal size, but got [185, 5120] at entry 0 and [173, 5120] at entry 1
2025-07-24 22:42:40,427 - __main__ - INFO - üéØ Processing CWE: CWE-89
2025-07-24 22:42:40,427 - __main__ - INFO - üéØ Creating steering vectors for CWE-89
2025-07-24 22:42:40,427 - __main__ - INFO - üìä Creating steering vectors from 3 vulnerable and 3 secure examples
2025-07-24 22:42:42,086 - __main__ - ERROR - ‚ùå Error processing CWE-89: stack expects each tensor to be equal size, but got [89, 5120] at entry 0 and [143, 5120] at entry 1
2025-07-24 22:42:42,113 - __main__ - INFO - 
üéâ CWE Steering Experiment Complete!
2025-07-24 22:42:42,113 - __main__ - ERROR - ‚ùå No results generated - experiment failed
