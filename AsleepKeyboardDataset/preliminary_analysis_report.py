#!/usr/bin/env python3
"""
Generate preliminary analysis report from validated completions
"""

import json
import os
from datetime import datetime
from collections import defaultdict
import glob

def analyze_validated_completions():
    # Find validated file
    validated_files = glob.glob("*_validated.jsonl")
    # Exclude double-validated files
    validated_files = [f for f in validated_files if not f.endswith("_validated_validated.jsonl")]
    if not validated_files:
        print("No validated files found")
        return
    
    latest_file = max(validated_files)
    print(f"Analyzing: {latest_file}")
    
    # Statistics
    stats = {
        'total': 0,
        'syntactically_valid': 0,
        'compilable': 0,
        'vulnerable': 0,
        'by_cwe': defaultdict(lambda: {
            'total': 0,
            'valid': 0,
            'compilable': 0,
            'vulnerable': 0,
            'vulnerability_patterns': defaultdict(int),
            'sample_vulnerabilities': []
        }),
        'by_language': defaultdict(lambda: {
            'total': 0,
            'valid': 0,
            'vulnerable': 0
        })
    }
    
    # Process validated completions
    with open(latest_file, 'r') as f:
        for line in f:
            try:
                data = json.loads(line)
                
                # Extract CWE
                scenario_id = data['scenario_id']
                cwe = scenario_id.split('/')[1].split('-')[0] + '-' + scenario_id.split('/')[1].split('-')[1]
                language = data.get('language', 'unknown')
                
                # Update stats
                stats['total'] += 1
                stats['by_cwe'][cwe]['total'] += 1
                stats['by_language'][language]['total'] += 1
                
                if data.get('syntactically_valid'):
                    stats['syntactically_valid'] += 1
                    stats['by_cwe'][cwe]['valid'] += 1
                    stats['by_language'][language]['valid'] += 1
                
                if data.get('compilable'):
                    stats['compilable'] += 1
                    stats['by_cwe'][cwe]['compilable'] += 1
                
                if data.get('vulnerable'):
                    stats['vulnerable'] += 1
                    stats['by_cwe'][cwe]['vulnerable'] += 1
                    stats['by_language'][language]['vulnerable'] += 1
                    
                    # Track patterns
                    for pattern in data.get('vulnerability_patterns', []):
                        stats['by_cwe'][cwe]['vulnerability_patterns'][pattern] += 1
                    
                    # Save sample
                    if len(stats['by_cwe'][cwe]['sample_vulnerabilities']) < 3:
                        stats['by_cwe'][cwe]['sample_vulnerabilities'].append({
                            'scenario_id': scenario_id,
                            'patterns': data.get('vulnerability_patterns', []),
                            'completion_preview': data['completion'][:200] + '...' if len(data['completion']) > 200 else data['completion']
                        })
                        
            except Exception as e:
                print(f"Error processing line: {e}")
    
    # Generate report
    report = f"""# Preliminary Analysis Report - AsleepKeyboardDataset Completions

**Generated**: {datetime.now().isoformat()}
**Based on**: {stats['total']} validated completions
**Model**: bigcode/starcoderbase-1b
**Temperature**: 0.6

## Executive Summary

We have analyzed {stats['total']} code completions generated by StarCoder-1B at temperature 0.6. This preliminary analysis reveals interesting patterns in both code quality and security vulnerabilities introduced by the model.

## Overall Statistics

| Metric | Count | Percentage |
|--------|-------|------------|
| Total Completions | {stats['total']} | 100.0% |
| Syntactically Valid | {stats['syntactically_valid']} | {stats['syntactically_valid']/stats['total']*100:.1f}% |
| Compilable | {stats['compilable']} | {stats['compilable']/stats['total']*100:.1f}% |
| Contains Vulnerabilities | {stats['vulnerable']} | {stats['vulnerable']/stats['total']*100:.1f}% |

## Key Findings

### 1. Code Quality
- **{stats['syntactically_valid']/stats['total']*100:.1f}%** of completions produce syntactically valid code
- The model struggles with proper syntax in approximately {100 - stats['syntactically_valid']/stats['total']*100:.1f}% of cases
- Temperature 0.6 provides a balance between diversity and coherence

### 2. Security Analysis

#### Vulnerability Rate by CWE Type

| CWE | Type | Total | Valid | Vulnerable | Rate |
|-----|------|-------|-------|------------|------|
"""
    
    # CWE mapping
    cwe_names = {
        'CWE-502': 'Deserialization of Untrusted Data',
        'CWE-89': 'SQL Injection',
        'CWE-78': 'OS Command Injection',
        'CWE-798': 'Hardcoded Credentials',
        'CWE-79': 'Cross-site Scripting',
        'CWE-22': 'Path Traversal',
        'CWE-125': 'Out-of-bounds Read',
        'CWE-787': 'Out-of-bounds Write',
        'CWE-190': 'Integer Overflow',
        'CWE-476': 'NULL Pointer Dereference',
        'CWE-416': 'Use After Free',
        'CWE-119': 'Buffer Overflow',
        'CWE-732': 'Incorrect Permission Assignment',
        'CWE-434': 'Unrestricted Upload',
        'CWE-200': 'Information Exposure',
        'CWE-522': 'Insufficiently Protected Credentials',
        'CWE-20': 'Improper Input Validation'
    }
    
    # Sort by vulnerability rate
    sorted_cwes = sorted(
        [(cwe, data) for cwe, data in stats['by_cwe'].items() if data['total'] > 0],
        key=lambda x: x[1]['vulnerable'] / x[1]['total'] if x[1]['total'] > 0 else 0,
        reverse=True
    )
    
    for cwe, data in sorted_cwes:
        cwe_name = cwe_names.get(cwe, 'Unknown')
        vuln_rate = data['vulnerable'] / data['total'] * 100 if data['total'] > 0 else 0
        report += f"| {cwe} | {cwe_name} | {data['total']} | {data['valid']} | {data['vulnerable']} | {vuln_rate:.1f}% |\n"
    
    report += f"""
### 3. Vulnerability Patterns

#### Most Common Vulnerability Patterns
"""
    
    # Aggregate all patterns
    all_patterns = defaultdict(int)
    for cwe_data in stats['by_cwe'].values():
        for pattern, count in cwe_data['vulnerability_patterns'].items():
            all_patterns[pattern] += count
    
    # Sort by frequency
    sorted_patterns = sorted(all_patterns.items(), key=lambda x: x[1], reverse=True)
    
    for pattern, count in sorted_patterns[:10]:
        report += f"- **{pattern}**: {count} occurrences\n"
    
    report += f"""
### 4. Language-Specific Analysis

| Language | Total | Valid | Valid % | Vulnerable | Vuln % |
|----------|-------|-------|---------|------------|--------|
"""
    
    for lang, data in sorted(stats['by_language'].items()):
        valid_pct = data['valid'] / data['total'] * 100 if data['total'] > 0 else 0
        vuln_pct = data['vulnerable'] / data['total'] * 100 if data['total'] > 0 else 0
        report += f"| {lang} | {data['total']} | {data['valid']} | {valid_pct:.1f}% | {data['vulnerable']} | {vuln_pct:.1f}% |\n"
    
    report += """
## Detailed Analysis by CWE

"""
    
    # Show top 5 most vulnerable CWEs with examples
    for i, (cwe, data) in enumerate(sorted_cwes[:5]):
        if data['vulnerable'] == 0:
            continue
            
        cwe_name = cwe_names.get(cwe, 'Unknown')
        vuln_rate = data['vulnerable'] / data['total'] * 100
        
        report += f"""### {i+1}. {cwe}: {cwe_name}
- **Vulnerability Rate**: {vuln_rate:.1f}% ({data['vulnerable']}/{data['total']})
- **Common Patterns**: {', '.join(sorted(data['vulnerability_patterns'].keys(), key=data['vulnerability_patterns'].get, reverse=True)[:3])}

"""
        
        if data['sample_vulnerabilities']:
            report += "**Sample Vulnerable Completions:**\n\n"
            for j, sample in enumerate(data['sample_vulnerabilities'][:2]):
                report += f"Example {j+1} ({sample['scenario_id']}):\n"
                report += f"```\n{sample['completion_preview']}\n```\n"
                report += f"Patterns detected: {', '.join(sample['patterns'])}\n\n"
    
    report += f"""
## Implications

### For AI Security Research
1. **Temperature Impact**: At temperature 0.6, the model shows moderate vulnerability introduction rates
2. **CWE-Specific Behavior**: The model exhibits different vulnerability rates for different CWE types
3. **Pattern Recognition**: Clear patterns emerge in how the model introduces vulnerabilities

### For Developers
1. **Code Review**: All AI-generated code requires careful security review
2. **High-Risk Areas**: Pay special attention to deserialization, SQL queries, and credential handling
3. **Validation**: {100 - stats['syntactically_valid']/stats['total']*100:.1f}% syntax error rate indicates need for validation

## Next Steps

1. Complete analysis of all 89 scenarios (currently {len(stats['by_cwe'])} CWE types analyzed)
2. Compare results across different temperatures
3. Evaluate mitigation strategies (prompting techniques, post-processing)
4. Test with larger models (StarCoder-15B, CodeLlama)

## Methodology Notes

- **Model**: bigcode/starcoderbase-1b
- **Temperature**: 0.6 (balances diversity and coherence)
- **Completions per scenario**: 25
- **Validation**: Syntax checking + compilation testing + vulnerability pattern detection
- **Languages**: Python, C, JavaScript

---

*This is a preliminary report based on {stats['total']} completions. Full analysis pending completion of all 2,225 generations.*
"""
    
    # Save report
    report_file = f"preliminary_analysis_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.md"
    with open(report_file, 'w') as f:
        f.write(report)
    
    print(f"\nReport saved to: {report_file}")
    
    # Print summary
    print("\nSUMMARY:")
    print(f"Total completions analyzed: {stats['total']}")
    print(f"Syntactically valid: {stats['syntactically_valid']/stats['total']*100:.1f}%")
    print(f"Contains vulnerabilities: {stats['vulnerable']/stats['total']*100:.1f}%")
    print(f"\nTop 3 most vulnerable CWEs:")
    for cwe, data in sorted_cwes[:3]:
        if data['vulnerable'] > 0:
            rate = data['vulnerable'] / data['total'] * 100
            print(f"  - {cwe}: {rate:.1f}% vulnerable ({data['vulnerable']}/{data['total']})")

if __name__ == "__main__":
    analyze_validated_completions()